{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "open_api_key=\"Key\"\n",
    "os.environ[\"OPENAI_API_KEY\"]=open_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic Prompt Summarization\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import(\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "filename = \"Data/fourth-ai-inflection.pdf\"\n",
    "\n",
    "pdfObj = open(filename, 'rb')\n",
    "\n",
    "# Use PdfReader instead of PdfFileReader\n",
    "reader = PyPDF2.PdfReader(pdfObj)\n",
    "speech = reader.pages[0].extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_messages=[\n",
    "    SystemMessage(content='You are a summarisation specialist and work for the top tier management like CEO, CTO, CFO etc. They do not have time to read long articles so you help them with Abstract Summary of the same. You do not miss any detail plus specially highlights all the key elements from the articles or long text'),\n",
    "    HumanMessage(content=f'Please provide an abstractive summary of the following text:\\n TEXT: {speech}')\n",
    "]\n",
    "\n",
    "llm=ChatOpenAI(model_name='gpt-4o')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/talib/anaconda3/envs/tf_env/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "##total tokens\n",
    "response_gpt4o = llm(chat_messages).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The latest AI hype cycle, epitomized by ChatGPT, has surpassed previous fads like the crypto mania of 2021 and the metaverse, generating extensive commercial, consumer, and philosophical interest. This rapid development has prompted governmental discussions on regulations and calls for a research moratorium to assess its human impact. Historical patterns suggest that such hype is often followed by a decline in mass interest, leading either to extinction or a period of pragmatic maturity. Despite the hype, the underlying AI technologies have been evolving over years and are now poised to drive a fourth wave of AI-driven business value. This briefing emphasizes that the current moment is an inflection point and advises companies on how to harness this new AI wave for business value, while also considering the practical limitations and necessary cautions for implementation.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_gpt4o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load the book\n",
    "loader = PyPDFLoader(\"Data/trustworthy-ai-implementing-eu-ai-act.pdf\")\n",
    "pages = loader.load()\n",
    "\n",
    "# Combine the pages, and replace the tabs with spaces\n",
    "text = \"\"\n",
    "\n",
    "for page in pages:\n",
    "    text += page.page_content\n",
    "    \n",
    "text = text.replace('\\t', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This document has 10708 tokens in it\n"
     ]
    }
   ],
   "source": [
    "num_tokens = llm.get_num_tokens(text)\n",
    "\n",
    "print (f\"This document has {num_tokens} tokens in it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\"], chunk_size=10000, chunk_overlap=500)\n",
    "\n",
    "docs = text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Implementing the EU AI Act in the UK as a value driverTrustworthy AIMay 2024Artificial intelligence (AI) is a key technology for digital  \\ntransformation in private and public organisations. By 2030,  \\nwe expect that AI will be a direct or indirect comp onent in all \\nprocesses and products along the entire value chain . From smart \\nwashing machines to (partially) autonomous vehicles , from \\nautomated application processing to intelligent cha tbots, and \\nfrom optimised maintenance processes to production robots – \\nthe rapid spread of AI can be seen all around. \\nIn addition to the economic relevance of use cases,  trust in the \\nperformance, security, reliability, and fairness of  AI is an essential \\nfactor in deciding for or against the use of AI sys tems. Both \\ndimensions are inextricably linked because, in prac tice, economic \\nefficiency and trustworthiness are mutually depende nt on the  \\nuse of AI. Finally, the use of the technology requi res certainty  \\nand trust on the part of users, customers, and deci sion-makers, \\nwhich only sound governance based on best practices  and \\ngenerally accepted standards can provide.\\nFor this reason, the institutions of the European Union  \\nhave developed and launched harmonised regulations  \\nfor AI systems. This comprehensive “EU AI Act” is directly \\napplicable in the member states and affects both private  \\nand public organisations – regardless of whether they are \\nproviders or deployers of an AI system. Though regulated in  \\nthe EU, it's important to note the regulation's  extra-territorial \\nextent. The EU AI Act will have a tangible impact on UK \\nbusinesses if they provide AI systems on the EU market,  \\ndeploy AI systems in the EU, or provide and deploy AI  \\nWsystems elsewhere if the output is used in the EU. The regulation aims both to promote European AI val ue creation \\nthrough uniform standards and to protect EU citizen s. The EU AI \\nAct is the first comprehensive law that aims to set  a global \\nstandard with regards to holistic AI governance, pr omoting the \\ndevelopment and use of high-quality AI systems and making the \\nrisks of AI systems manageable and transparent thro ughout the \\nentire lifecycle. Given its global importance, orga nisations should \\nprioritise aligning with the regulation in order to  gain a strong first \\nmover advantage by balancing their legally complian t \\nimplementation of the requirements in and around AI  systems \\ncase-by-case at an early stage. Otherwise, those af fected expose \\nthemselves to many legal risks, these include not o nly potential \\nfines under the EU AI Act, but also fines under the  GDPR,  \\nand industry-specific regulations, or also liabilit y claims if they \\nuse a defective AI system.\\nHowever, implementing diverse regulations not only poses \\nchallenges for organisations but also opens opportu nities for \\nthem to improve their AI in terms of quality. This is all the more \\ntrue because the increasing use of AI puts the resp onsible \\nhandling of data more strongly than ever before in the focus  \\nof Corporate Social Responsibility – companies‘ res ponsibility  \\nfor the environment and society. With the right app roach and  \\nthe corresponding interdisciplinary competencies in  AI \\ngovernance and law, organisations can avoid efforts  and risks, \\nshorten (market) introduction times for their AI sy stems and take \\na pioneering role in digital transformation with AI .Foreword2 | PwC | Trustworthy AIMay 2024Scaling\\nAI systems are finding broader and more intensive a pplications \\nand are thus increasingly becoming a core component  of global \\nvalue creation. PwC 27th UK CEO Survey1. This is also imperative \\nbecause AI systems generate the greatest added valu e when \\nthey are applied on a large scale and quickly move beyond the \\npilot phase. Economies of scale take on a central r ole in AI \\nprojects because high fixed costs in development me et low \\nmarginal costs in operation.\\n1 PwC 27th UK CEO Survey\\n2 Politico “Dutch scandal serves as a warning for Europe over risks of using algorithms” 2022However, there is often a lack of adequate AI governance \\nsystems to operationalise and subsequently scale AI-enabled \\nsolutions. Without them, operating the system becomes a risk \\nto an organisation’s reputation and profitability. In addition, the \\nuse of AI without adequate monitoring and governance systems \\ncan have a tangible negative impact on the quality of life of \\nmany people in a critical situation, as the child benefit scandal \\nin the Netherlands showed, where migrants were discriminated \\nagainst for years by an algorithm.2\\nNevertheless, Around 52% of CEOs point to a lack of skills in \\nthe workforce as a key challenge in implementing AI1. Under \\nthese circumstances, there are immense challenges in  making  \\nAI systems safe, robust, fair, and effective.The synergy potential  \\nof scaling and regulation\\n1.3 | PwC | Trustworthy AIMay 2024Regulation\\nThe EU AI Act imposes several far-reaching requirem ents on many \\nAI systems. The regulation is expected to have a si milar impact on \\nthe affected AI systems as, for example, the Genera l Data  \\nProtection Regulation (GDPR) had on the processing of  \\npersonal data.\\nIn addition to the general regulation of AI by the EU AI Act, other \\nrequirements are relevant to AI use cases: Horizont al ones, such \\nas the GDPR or the EU Data Act, and vertical or sec toral ones, \\nsuch as the UK Automated Vehicles Bill.\\nAlready today, 64% of CEOs cite the regulatory envi ronment  \\nas barrier to implementing AI systems1 – a proportion that will \\nincrease significantly with the entry of the EU AI Act into force.  \\nTo ensure that AI governance can address the multip le legal and  \\ntechnical aspects, aligning it with the regulatory framework early \\non is crucial. Failures are difficult to correct in  retrospect and can \\nlead to unintended liability risks, increased costs , or inefficient \\nallocation of resources in AI development.Building bridges between scaling and regulation\\nSo are organisations only implementing AI governance for \\ncompliance reasons? In our experience, it is an opportunity to \\nmanage and improve AI transformation. A closer look  at the EU \\nAI Act reveals a great deal of overlap between the requirements \\nset in regulation and the structures necessary for operationalising \\nand scaling AI systems. Conformity assessments and specific \\ndocumentation requirements are, of course, primarily relevant \\nfrom a compliance perspective. However, flexible da ta, risk, and \\nlifecycle management systems, especially, are indispensable to \\nenable organisations to successfully transition their AI systems \\nfrom the pilot phase to scaled operations.\\nSelection of relevant legal norms for the use of AI\\nDevelopment and \\noperation of AI systems \\nin the EUEU AI ACT\\nAccess to data by (end) \\nusers or third partiesEU DATA ACT\\nOTHER  \\nREGULATIONSSensitive data  \\nfor model training \\nand explainabilityGDPR\\nVehicles with autonomous \\ndriving functionUK Automated \\nVehicles Bill\\n1 PwC 27th UK CEO Survey4 | PwC | Trustworthy AIMay 20242.\\nQuo vadis EU AI Act?\\nThe EU AI Act is a regulation of the European Union  to define harmonised regulations for systems with artificial intelligence.  \\nThe term “AI system” is very broadly defined in the  EU AI Act:The EU AI Act and  \\nits implications\\n“AI system” means a machine-based system designed t o operate with varying levels of autonomy, that may  exhibit adaptiveness \\nafter deployment and that, for explicit or implicit  objectives, infers, from the input it receives, ho w to generate outputs such as \\npredictions, content, recommendations, or decisions  that can influence physical or virtual environment s.6\\nThe EU Commission's original proposal for the regul ation of  \\nAI systems was published in April 2021 and was revi sed and \\namended several times during the legislative proces s before \\nfinally being adopted in 2024. After the EU AI Act comes into \\nforce, transitional periods are provided for until it takes effect, \\nwithin which organisations must implement the requi rements. \\nThe deadlines are (with minor deviations) 6 months for prohibited \\nAI systems, 12 months for general purpose AI (GPAI)  systems, \\n24 months for high-risk AI systems in accordance wi th Annex \\nIII and finally up to 36 months for high-risk AI sy stems in \\naccordance with Annex I. After this period, non-com pliance \\ncould result in significant fines of up to 35 milli on euros or  \\n7% of the previous year's global turnover for compa nies that \\nfail to comply with the prohibitions and 15 million  euros or 3% \\nof the previous year's global turnover for companie s that fail to \\ncomply with the rules for high-risk or GPAI systems .3\\nThe impact of the EU AI Act on private and public organisations \\nis complex and must be determined on a case-by-case basis.  \\nIn the following sections, we therefore take a look at the three \\nessential aspects of the regulation: the role of regulated  \\norganisations, the risk classification of AI system s and the \\nrequirements for high-risk AI systems and GPAI systems. We \\nalso look at the challenges involved in practical implementation \\nand conclude by outlining a solution.What does this mean for UK businesses?\\nThe AI Act sets out specific requirements for ‘providers’ and \\n‘deployers’ of AI systems and businesses affected will fall into \\nthree domains:\\n• Providers are those who develop AI systems and “have an AI \\nsystem developed with a view to placing it on the market or \\nputting it into service under its own name or trademark, \\nwhether for payment or free of charge”. An example of a \\nprovider is OpenAI, where they develop base foundation \\nmodels. The scope is those AI systems established within the \\nEU or in a third country placing AI systems on the EU market.\\n• Users (‘deployers’) are “any natural or legal person, public \\nauthority, agency or other body using an AI system under its \\nauthority”. Those using AI systems in the context of personal \\nor non-professional activity are exempt from the\"),\n",
       " Document(page_content='whether for payment or free of charge”. An example of a \\nprovider is OpenAI, where they develop base foundation \\nmodels. The scope is those AI systems established within the \\nEU or in a third country placing AI systems on the EU market.\\n• Users (‘deployers’) are “any natural or legal person, public \\nauthority, agency or other body using an AI system under its \\nauthority”. Those using AI systems in the context of personal \\nor non-professional activity are exempt from the \\nrequirements. A deployer could be a business that uses  \\na provider’s API to embed AI within their own products, \\nfine-tunes a foundation model to develop a specialised \\nproduct, or may simply use AI systems as internal tools.\\n• Providers and Users (‘deployers’) of AI systems located in  \\na third country, where the output produced by the AI systems \\nis intended to be used in the EU.\\n3 Current version of the AI regulation as of 13 March 20245 | PwC | Trustworthy AIMay 2024\\nExample 1:\\nA company or public body changes the intended purpose \\nof an AI system already placed on the market or put into \\noperation by a third party, which does not pose a high risk, \\nin such a way that the modified AI system becomes a \\nhigh-risk AI system.Example 2:\\nA distributor who considers or has reason to believe that a \\nthird-party high-risk AI system that it has made available \\non the market does not comply with the requirements of \\nthe EU AI Act shall take necessary measures to bring that \\nsystem into compliance, withdraw or recall it, or ensure \\nthat the supplier, the importer or any other relevant actor, \\nas appropriate, takes appropriate corrective action.Addressees in the AI value chain \\nAt the centre of the regulation are the deployers and providers \\nof AI systems. They bear the main burden of the requirements. \\nOn the one hand, these are providers who place regulated  \\nAI systems on the market or put them into operation in the \\nEuropean Union, regardless of whether these providers are \\nestablished in the EU or in a third country, as well as deployers \\nof regulated AI systems who are established in the European \\nUnion. In addition, it also applies to providers and deployers  \\nof regulated AI systems established or resident in a third \\ncountry if the result produced by the system is used in the \\nEuropean Union. The EU AI Act thus has an extraterr itorial \\napplication and also indirectly regulates beyond the borders  \\nof the European Union and the European Economic Area.\\nUnder certain circumstances, the EU AI Act also places other \\nactors, such as importers, distributors or manufacturers of \\nhigh-risk AI systems, on an equal footing with prov iders in  \\nterms of their obligations (see example 1).\\nAt the same time, the deployers, representatives of  the providers \\n(so-called authorised representatives), importers a nd distributors \\nof high-risk AI systems are required to ensure the extensive  \\nobligations of the providers – insofar as this is t heir responsibility \\n(see example 2). \\n \\nIn order to ensure compliance with the requirements of the  \\nEU AI Act across the entire value chain, the obligations of \\ndeployers of high-risk AI systems apply alongside the \\nrequirements of other stakeholders. Deployers, i.e. natural or \\nlegal persons, including public authorities, institutions or other \\nbodies under whose responsibility the system is used, are \\nobliged, among other things, to ensure human oversight and \\nmust ensure that input data is subject to the specifi ed purpose  \\nof the high-risk AI system.\\nIn fact, the involvement of the various stakeholders means that \\nevery organisation dealing with AI systems must define and \\ncontinuously review its own role in order to fulfil its obligations \\ncorrectly. Furthermore, this involvement means that purchasers \\nof AI systems in particular should optimise their legal position \\nvis-à-vis manufacturers, providers and distributors. For \\nexample, drafting a contract under IT law offers the opportunity \\nto ensure specific performance obligations, such as support \\nand maintenance in particular, to ensure the suitability of the AI \\nsystem for use within the scope of the EU AI Act under warranty \\nfor defects law and to enable recourse under liability law.\\nMay 20246 | PwC | Trustworthy AIAI systems with unacceptable risks  are prohibited per se. \\nThese include, for example, systems for the subliminal  \\nmanipulation of people or certain biometric real-time \\nrecognition systems in public spaces.  \\nHigh-risk AI systems  are at the centre of the regulation. These \\nare permitted, but in order to develop and use them, they must comply with comprehensive documentation, monitoring and \\nquality requirements. The group of high-risk AI systems \\ncomprises use cases defined by the Commission, some of \\nwhich are sector-specific and presented on the next page.Classification of AI systems \\nThe EU AI Act divides AI systems into several categories based \\non their risk characteristics, which are either permitted without \\nrestriction, permitted under certain conditions or prohibited.  This approach is based on an assessment of the expected  \\nrisks that a particular AI system may pose to the health, safety \\nor fundamental rights of EU citizens.\\nMinimal-risk AI systemsHigh-risk AI system requirements\\nAI systems with additional transparency requirementsGPAI system requirements\\n•    Risk management system\\n•    Data governance\\n•    Technical documentation\\n•    Record-keeping\\n•    Transparency obligations\\n•    Human oversight\\n•    Accuracy\\n•    Robustness and cyber securityAll GPAI (General Purpose AI)\\n•  Technical documentation, instructions for use, \\nCompliance with the Copyright Directive \\nand publication of a summary of the training \\ncontent\\nGPAI with systemic risks\\n•  Model evaluation, tracking, documenting and \\nreporting about serious incidents, cyber securityProhibited AI systems\\nMay 2024\\nMay 20247 | PwC | Trustworthy AIMay 2024AI systems with a general purpose of use (GPAI) were most \\nrecently included in the regulation. Providers of G PAI systems4 \\nmust create technical documentation, provide instru ctions for \\nuse, draw up guidelines for compliance with EU copy right law \\nand publish a summary of the content used for train ing. Providers \\nof GPAI systems that pose a systemic risk should al so carry out \\nstandardised model evaluations such as adversarial testing, \\nmitigate systemic risks, track and report serious i ncidents and \\nensure cybersecurity protection.\\nDeployers and providers of certain AI systems with a direct or \\nindirect impact on human end users are also subject  to increased \\ntransparency obligations . This includes systems that are \\ndesigned to interact with people or expose natural persons  \\nto biometric categorisation, for example. Certain s ystems that  \\n4 Some providers of GPAI systems with a free and open license and without systemic risks are partially excluded.are used to generate or manipulate images, video, s ound or text \\nare also affected. Deployers and providers are obli ged to ensure \\nthe transparency of these AI systems towards end us ers in future.\\nAI systems that do not fall into any of the aforeme ntioned risk \\ncategories are considered to have a minimal risk . They are \\npermitted without additional requirements. However,  the EU \\nCommission is authorised to adapt the list of regul ated AI \\nsystems and add further use cases.High-risk AI systems according to Annex I\\nHigh-risk AI systems according to Annex III\\n•  Biometric systems\\n• Critical infrastructure\\n• Education\\n• Human Resources•   Essential private and public  \\nservices, including finance  \\nand insurance\\n• Law enforcement• Migration, asylum and border controls\\n•  Administration of justice and  \\ndemocratic processesSection A –  High-risk AI systems for which flexibility in the implementation of compliance is granted to avoid double \\nregulatory burden:\\n• Machines \\n• Toy safety\\n•  Recreational craft and personal \\nwatercraft\\n• Lifts and safety components for lifts•  Equipment and protective systems  \\nin potentially explosive atmospheres\\n• Radio equipment\\n• Pressure equipment\\n• Ropeways • Personal protective equipment \\n•  Appliances for burning gaseous fuels\\n• Medical devices\\n• In-vitro diagnostics\\nSection B –  High-risk AI systems that are regulated by sector but exempt from most requirements:\\n• Civil aviation security \\n• Two-, three- and four-wheeled vehicles\\n•  Agricultural and forestry vehicles •  Motor vehicles and motor vehicle \\ntrailers as well as systems, components \\nand separate technical units for  \\nthese vehicles• Marine equipment \\n• Interoperability of the railway systemHigh-risk AI systems according to Annex I and III\\nMay 20248 | PwC | Trustworthy AI\\n8 | PwC | Trustworthy AI9 | PwC | Trustworthy AI\\nChallenges of a legally compliant risk classification \\nThe correct, i.e., legally compliant, allocation of  AI systems to  \\none of the risk categories of the EU AI Act is a de cisive factor in \\navoiding the threat of massive fines due to missing  or insufficient \\ncompliance. In addition to its role in AI value cre ation, it also plays \\na key role in defining the requirements that must b e met by the \\norganisation and the AI system in accordance with t he EU AI Act.\\nHowever, one example illustrates that it can be cha llenging for \\norganisations to classify use cases in a legally co mpliant way:  \\nIn the face of advancing digitalisation, employers are increasingly \\nopting to use systems that enable targeted advertis ing and \\nefficient recruitment of qualified employees. Given  the broad \\ndefinition of AI systems in the EU AI Act as well a s the definition \\nfor classifying use cases in the application and se lection process \\nas high-risk AI systems, the following question wil l arise in the \\nfuture: Is the use of supporting software in these areas already \\nsubject to the comprehensive requirements of the EU  AI Act? \\nThe EU AI Act itself does not provide for a concretisation  \\nof this definition. Rather, it will be important – following'),\n",
       " Document(page_content='definition of AI systems in the EU AI Act as well a s the definition \\nfor classifying use cases in the application and se lection process \\nas high-risk AI systems, the following question wil l arise in the \\nfuture: Is the use of supporting software in these areas already \\nsubject to the comprehensive requirements of the EU  AI Act? \\nThe EU AI Act itself does not provide for a concretisation  \\nof this definition. Rather, it will be important – following  \\nthe case law of the European Court of Justice (ECJ) – to \\ndetermine the classification into risk categories per the  \\npurpose and recitals of the legislator, relevant case law,  \\nand recognised methods of inter-pretation to enable a  \\nselective and judicially robust classification.\\nLegally compliant risk classification is relevant n ot only in the \\ncontext of the EU AI Act but also because of the pr oposal for  \\nthe EU AI Liability Directive published in Septembe r 2022. This \\nregulates the liability of deployers, distributors and manufacturers \\nfor damage caused by AI systems and takes up the ri sk levels of \\nthe EU AI Act. The classification thus also has con sequences for \\nthe assessment of liability risks. Those who miscla ssify AI systems \\nmust consequently expect both fines and civil liabi lity in the event \\nof missing or unreliable AI governance and document ation.AI Liability Directive\\nThe proposal to harmonise liability rules for damage \\ncaused by the use of artificial intelligence builds  \\non the definitions established in the EU AI Act. The \\nCommission assumes that the proof of damage caused \\nby the breach of a statutory duty is partly impossible  \\nor, at any rate, associated with considerable difficulties \\nfor injured parties of AI systems. To counteract this,  \\nthe EU AI Liability Directive provides that causality \\nshould be presumed under certain conditions. In \\nparticular, the risk classification under the EU AI Act \\nplays a role. A right of access to information and,  \\nthus, evidence in cases involving high-risk AI systems \\nflanks the facilitation of proof of causality.\\nMay 2024May 2024Requirements for high-risk AI systems \\nThe EU AI Act requirements for high-risk AI systems are \\nextensive and pose complex challenges for organisations. The \\nfollowing overview shows the key requirement areas for high-risk  \\nAI systems under the EU AI Act:\\nDue to the heterogeneity of AI systems, the requirements  \\nin the EU AI Act have been deliberately formulated in a  \\ngeneral and abstract manner by the European legislator.  \\nThe major challenge in practice is to operationalise these \\nrequirements so that they can be seamlessly integrated into \\ntechnical and organisational processes and, at the same time, \\nprovide legal certainty. \\nTo implement the regulation in an innovation-friendly and \\nefficient manner, the requirements should be integrated  \\nor merged as far as possible into existing processes and \\nstructures, such as IT compliance systems. If this is not  \\ndone, redundant structures and processes will increase \\npersonnel and IT-related expenses. Moreover, there is a  \\nrisk of inconsistencies in assess-ment and documentation,  \\nand acceptance of compliance with the legal requirements  \\nin IT and operational business units will decline.\\nAn example of an overlap between existing compliance \\nprocesses and the future regulations of the EU AI Act is  \\nthe assessment of risks: While the EU AI Act requires an \\nassessment of expected risks to health, safety, or  \\nfundamental rights, the GDPR requires a “data protection \\nimpact assessment” in the event of expected high risks  \\nto the rights and freedoms of data subjects. From a corporate social governance perspective, a data ethics \\nrisk assessment may also need to be added to address whether \\nsuch processing is warranted. All these legal risk assessments \\nshould be bundled into one process, embedded in a – possibly \\noverarching – compliance management system and subject to a \\ntechnical assessment with a consistent benchmark. This allows \\nexisting processes and documentation to be used and aligned \\nwith each other, thus avoiding risks of incongruence associated \\nwith compliance and creating efficiency.\\nThere is also more work to be done by the EU institutions in  \\nthe context of standardisation if they want to create regulation \\nthat promotes innovation as promised. At the level of a concrete \\nAI use case, the reality of AI systems and regulatory ideas can \\nquickly diverge. For human oversight, for example, the EU  \\nAI Act stipulates that it takes at least two people to verify the \\nresults of biometric identification with AI systems. However, \\nwhether humans are actually able to improve monitoring and \\ndecision-making in the relevant fields of application is \\nquestionable. Therefore, the specifications work against \\nautomation and efficiency enhancement by AI systems  \\nin such cases.Resource Management  \\nAllocation, \\nRoles & Rights, \\nCapacity, \\nAccountability\\nTransparency  \\nRequirements, \\nInformation, \\nInstructions, \\nExplainabilityRisk Management  \\nIdentification, \\nAssessment, \\nPrevention & Mitigation, \\nMonitoring\\nDocumentation  \\nModel Cards, \\nData Sheets, \\nSystem Information, \\nRetentionData Management  \\nQuality Assessment, \\nAnnotation,  \\nChanges, Logging, \\nData Splits, Data Protection\\nConformity Assessment  \\nAudit,  \\nDeclaration, \\nCE Marking, \\nAdjustmentsLifecycle Management  \\nDevelopment & Operation, \\nPerformance, Tests,  \\nRobustness, Monitoring & \\nOversight, (Cyber) Security\\nInteraction with Authorities  \\nRegistration, \\nCommunication, \\nAccess, \\nReporting\\nChallenges in implementing functional AI governance along the lines of the EU AI Act\\nMay 202410 | PwC | Trustworthy AI10 | PwC | Trustworthy AIMay 2024\\nCombining high-quality AI systems and AI compliance is the  \\nkey to scaling and, thus, to the success of sustainable value \\ncreation with AI systems. Both aspects require recognised \\nstandards, best practices, and appropriate tools. The goal: fast, \\nsecure, and efficient development and operation of AI systems.In the following, we want to outline an AI complian ce management \\nsystem that can be used step-by-step to build up organisation-\\nspecific AI governance that combines both aspects. To this end, \\nwe draw on concepts and principles from existing compliance \\nmanagement systems, which we blend with our experience and \\nthe requirements of the EU AI Act.Holistic AI governance for \\ncompliance and quality3.\\n1. Culture \\n•  Definition of a set of values for acting with \\nintegrity and in compliance with the rules\\n•  Consideration of legal, economic and  \\ntechnical aspects\\n•  Involvement and motivation of employeesCornerstones of compliance management systems\\n2. Goals and risks \\n•   Derivation of minimum requirements from \\ncorporate goals and strategy\\n•  Systematic risk analysis for the identification \\nand assessment of risk\\n•  Prioritisation of business areas and  \\nimplementation measures\\n6. Monitoring and  \\nimprovement \\n•  Implementation of intelligent \\nmonitoring mechanisms\\n•  Identification of improvement \\npotentials and errors throughout \\nthe lifecycle\\n•  Regular checks and tests as well \\nas audits to verify conformity3. Coordination \\n•  Definition and assignment  \\nof responsibilities\\n•  Design of reporting,  \\ndecision-making and escalation \\nchannels\\n•  Linkage and coordination with \\nother management systems\\n5. Communication and training \\n•  Communicating the defined value framework\\n•  Technical and legal training of employees\\n•  Increasing awareness by communicating \\ncompliance measures and their effects4. Programme \\n•  Implementation of prevention and \\nmitigation measures for risk\\n•  Orientation towards best practices and \\nrecognised standards\\n•  Design and development guides taking \\ninto account the lifecycle-specific aspects \\nof AI systems1 2\\n4 56 311 | PwC | Trustworthy AIEssential preparation \\nFirstly, for any organisation that develops, operates, uses, \\nimports, or distributes AI systems, it is important to prepare \\nthe setup of necessary compliance and governance \\ncomponents and develop a clear picture of the measures \\nrequired for its use cases.\\nQualification & value orientation  \\nFundamental to successful AI governance is not only  \\nthe development and documentation of new processes  \\nand structures but also their actual implementation by  \\nqualified people.\\nAs explained above, a lack of know-how is one of the biggest \\nbarriers to digital transformation. Training concepts that \\nestablish a common knowledge and value base concerning \\nartificial intelligence among all stakeholders and achieve buy-in \\nfor the AI-induced transformation offer a remedy here. \\nIn addition to the content imparted to participants, a continuous \\nexchange between stakeholders is particularly important. \\nEspecially between departments that are far removed regarding \\nresponsibilities, such as technical AI development and the legal \\ndepartment, suitable workshops can help build bridges in terms \\nof knowledge and generate targeted interactions for the \\npermanent involvement of the respective persons. Based on \\ncross-functional training, it is easier to find formats later in AI \\nprojects where different stakeholders jointly advance the \\ndevelopment, operationalisation, and control of the AI systems.\\nImpact assessment\\nIdentifying all AI projects in an organisation and their status \\n(e.g., planning, development, and operation) forms the basis for \\nall further decisions in establishing appropriate AI governance.  \\nIf organisations have subsequently classified risks and assigned \\nroles according to the requirements of the EU AI Act, an impact \\nassessment for individual AI use cases can help better assess \\nthe impact of AI regulation on the organisation. In addition to \\nthe EU AI Act, other horizontal and sectoral regulations should \\nalso be considered.Gap assessment \\nCarrying out a comparison of the existing structures and \\nprocesses with the previously identified compliance \\nrequirements makes it possible to determine concrete work'),\n",
       " Document(page_content='roles according to the requirements of the EU AI Act, an impact \\nassessment for individual AI use cases can help better assess \\nthe impact of AI regulation on the organisation. In addition to \\nthe EU AI Act, other horizontal and sectoral regulations should \\nalso be considered.Gap assessment \\nCarrying out a comparison of the existing structures and \\nprocesses with the previously identified compliance \\nrequirements makes it possible to determine concrete work \\npackages. A gap assessment also helps to identify overlaps \\nfrom different regulations and plan a uniform implementation. \\nExperience shows that many existing structures and processes \\ncan be expanded to include AI-specific measures, such as risk \\nmanagement, data management or cyber security.\\nCompliance strategy \\nThe final step of the preparation is defining a compliance \\nstrategy to establish a holistic AI governance and compliance \\nmanagement system. This includes a list of concrete measures \\nfor establishing AI governance and closing previously identified \\ngaps, the associated efforts, and a corresponding prioritisation. \\nThe prioritisation, on the one hand, results from the \\norganisation-specific goals in terms of compliance, quality, and \\nscaling the identified AI systems and, on the other hand, from a \\nrisk/impact analysis to define which regulations and business \\nareas should be focused on first. This also marks the beginning \\nof the implementation of the requirements of the EU AI Act.Example:  An organisation can align its AI governance  \\nwith existing IT governance processes and integrate it  \\ninto these. Use case management can be derived from  \\nIT demand and portfolio management. In turn, requirements \\nfor high-risk AI systems can be integrated into the software \\ndevelopment lifecycle. Of course, AI specifics must be taken \\ninto account here.12 | PwC | Trustworthy AI\\nMay 202413 | PwC | Trustworthy AI\\nModules of holistic AI governance\\nMeeting all the requirements of the EU AI Act and other \\nregulations is an undertaking that should not be un derestimated. \\nTherefore, it is worthwhile for all organisations to divide the \\nimplementation into smaller work packages and initially focus \\non governance components that bring immediate added value \\nbeyond the core compliance purpose. The implementation can \\nfollow an agile approach in which the organisation works on \\ndifferent components at different intensities simultaneously –  \\nalways based on the organisational goals, the identified \\ncompliance risks, and time restrictions.\\nThe modular approach has many benefits:  \\n• Quickly improving governance of AI initiatives. \\n• Enhancing the quality of AI systems from the begi nning.  \\n•  Successive and iterative work towards compliance  with  \\nrelevant requirements. In the following sections, we present several attra ctive modules \\nof holistic AI governance for compliant and high-qu ality AI systems \\nand highlight the specific challenges in their impl ementation.Example: A company can fall back on established \\nstructures in data management and, therefore, desig n \\neffective processes relatively quickly. On the othe r hand, \\nregarding documentation, it is better to start earl y with \\nstandardisation and collection – but only when it b ecomes \\nnecessary, for example, to push ahead with compilat ion \\nand preparation for an external audit.\\nRoles and responsibility structure\\nThe EU AI Act requires the establishment of role an d responsibility concepts for high-risk AI \\nsystems. It remains unclear how these shall be conc retely designed. It is, therefore, a good  \\nstart to fall back on best practices from other fie lds for concrete implementation. \\nThe necessary design varies between organisations, but the areas of responsibility and roles \\nwithin AI systems are often similar in practice. The basis for structured processes: clear delineation \\nof individual task areas and roles. Secondly, respo nsibilities for the individual task areas must be \\ndefined to avoid diffusion of responsibility and pr ovide clear contact persons for internal and \\nexternal stakeholders. In the future, this will als o include auditors and regulators. \\nIf organisations can link work steps and roles, the y can also reduce cases where entire process \\nchains collapse, e.g., due to the departure of esse ntial people because it was not clearly defined \\nwhich areas of responsibility needed to be re-staff ed. Depending on a risk assessment, high-risk \\nAI systems also lend themselves to concepts that pl ace additional requirements on the scope of \\nstaffing and representation of critical roles to en sure greater security and reliability.\\nIn role and responsibility concepts, restrictions a re necessary to meet specific security requirements , \\ndepending on the area of application. For example, in data management, it is (mandatory) to \\nestablish processes for granting and removing acces s rights to protect sensitive data. In principle, \\nthe actual necessity is decisive for granting such access rights (“need-to-know” basis). However, \\nthis is not always easy to determine in practice an d must, therefore, be clearly defined for \\ndecision-makers.\\nMay 2024Risk management\\nWith the use of AI, an organisation’s risk management requirements must be adapted. The EU AI \\nAct requires high-risk AI systems to establish, apply and document a risk management system \\n(RMS). This RMS can be understood as a continuous and iterative process that is carried out \\nthroughout the lifecycle of a high-risk AI system and requires regular, systematic updates. These \\ncan occur in defined cycles and on specific occasions, such as new findings from monitoring or \\nuser feedback. Furthermore, developing sufficient measures to prevent, mitigate, and reduce the \\nrisks to an acceptable level is required. \\nThe basis of adequate risk management is a systematic risk analysis. It serves to identify sources \\nof risks, determine probabilities of occurrence, and quantify impacts. In the context of AI, this area \\nof risk management probably poses the greatest challenges, as identifying scenarios and their \\neffects requires a great deal of expertise. From degradation of performance metrics due to the \\nchanging characteristics of input data to discrimination due to underrepresentation, there are many \\nways in which the health, safety or fundamental rights of EU citizens or the environment can be put \\nat risk. In some cases, a so-called “Fundamental Rights Impact Assessment” is also required by \\nthe applying organisation.\\nIt remains to be seen how standardisation in AI risk management will develop in the EU. Through \\ninternational regulatory exchange, especially with the US, there is at least a willingness to harmonis e \\nAI standards in many areas. This would allow the EU to build on existing international and national \\nstandards. For example, in January 2023, the NIST (US federal agency) published the “Artificial \\nIntelligence Risk Management Framework (AI RMF 1.0)”, the first national framework for AI risk \\nmanagement. The risk management guidelines from the  joint ISO and IEC technical committee on \\nartificial intelligence are also relevant (ISO/IEC 23894:2023). \\nFor some use cases, standardisation has already reached a higher level of maturity and detail and \\ncan at least provide conceptual guidance for future frameworks. One example is test scenarios for \\nautonomous vehicles (ISO 34502:2022), which can help with standardised testing and subsequent \\napproval. However, by no means will all organisations benefit from sector-specific standards as in \\nthe automotive sector. They cannot avoid determining detailed risk scenarios and probabilities of \\noccurrence for their use cases. Organisations will, therefore, continue to depend on the know-how \\nof (domain) experts for a comprehensive risk analysis.\\nMay 202414 | PwC | Trustworthy AIMay 2024Data management\\nHigh-quality data is essential for the development of good AI systems. Data management in the  \\nEU AI Act is, therefore, primarily about taking appropriate steps to achieve high data quality and \\nprotect data from access by unauthorised persons.\\nAn enormous challenge is the processing of data sets during development and operation. Thus,  \\nthe EU AI Act calls for specific and comprehensive quality criteria and safeguards. This results  \\nin several requirements: Data sets must be assessed regularly and transparently. Organisations \\nmust identify and define permissible and, where appropriate, desired biases. They must check the \\navailability, quantity, and suitability of the data sets and possible discrimination. Last but not least, \\nthey must identify potential data gaps or deficiencies.\\nHowever, the EU AI Act does not further specify these requirements. Regulated organisations must \\ndetermine, document, and constantly check the legal  minimum for the respective high-risk AI system \\nin question. This is associated with legal uncertai nty in individual cases and may lead to liability r isks. \\nAny data sets used and processed must also comply with data protection requirements in case \\nthey contain personal data (IP addresses, names, IDs, etc.). These requirements must be verifiably \\nmet at an early stage, in some cases even before th e development of the AI system begins. \\nRegardless of whether the data is collected by the provider of the AI system, provided by a third \\nparty, or even made available (publicly) by the dat a subject, compliance must be proven. In \\naddition, if copyright-protected content (e.g., texts, music) is used, it may be necessary to obtain \\ncorresponding rights of use in advance. \\nThe requirements of the GDPR extend not only to the AI system development phase (for example, \\nwith training data) but to the entire lifecycle of an AI system – i.e., for the input and further use as \\nwell as deletion and transfer of personal data. Organisations must evaluate data protection risks on \\na case-by-case basis for each form of processing of personal data in AI systems. The challenge in'),\n",
       " Document(page_content='corresponding rights of use in advance. \\nThe requirements of the GDPR extend not only to the AI system development phase (for example, \\nwith training data) but to the entire lifecycle of an AI system – i.e., for the input and further use as \\nwell as deletion and transfer of personal data. Organisations must evaluate data protection risks on \\na case-by-case basis for each form of processing of personal data in AI systems. The challenge in \\nthis context is the potential of AI systems with the principle of combining data protection through \\ndata protection-friendly default settings (“data protection by design”). Here, the newly adopted \\nstandard ISO 31700, “Privacy by design for consumer goods and services”, can provide guidance. \\nParticularly delicate: Responsibilities for compliance with data protection law and AI law regulations \\ncan diverge. This has implications for different areas of an organisation. While the EU AI Act mainly \\naddresses natural or legal persons, the GDPR links the responsibility to the body that determines \\nthe purposes and means of the data protection-related processing activity. Thus, it is conceivable \\nthat the use of a high-risk AI system in a group requires the parent company’s compliance with  \\nthe requirements of the EU AI Act while, at the same time, determining the means and purposes  \\nof processing.\\nMay 202415 | PwC | Trustworthy AIMay 2024Personal employee data is primarily determined by the HR department of the subsidiary, whereby \\nthe subsidiary is qualified as the data protection controller. Such cases must be identified and \\ndocumented to place the obligations of the EU AI Act in personnel terms. \\nThose who deal with the legal aspects early can better assess and, at best, reduce any liability \\nrisks. This includes, above all, drafting contracts with providers of AI systems or actors along  \\nthe supply chain in an advantageous way.\\nLifecycle management\\nThe requirements of the EU AI Act are intended to ensure high-quality levels for all high-risk AI \\nsystems in the market. Therefore, the regulation places particular emphasis on structured  \\nprocesses for the design, development, review and monitoring of AI systems. Furthermore, it \\nrequires that high-risk AI systems remain robust and accurate throughout their lifecycle. Combined \\nwith the already described requirements for responsibility management, data management and \\nrecording of logs and metadata, this results in the connection of abstract regulatory requirements \\nto proven workflows and architectures of so-called Machine Learning Operations (MLOps).9\\n Trustworthiness and compliance, at their core, require the implementation of best practices \\nthroughout the lifecycle of an AI system. The fundamental purpose of MLOps frameworks and \\ntechnologies is to build structured process flows that can manage AI systems from initiation to \\noperation – in some cases, even fully automatically.  \\nThose who successfully combine methods from the fields \\nof data management, software development and \\nmachine learning in MLOps enjoy far-rea-\\nching advantages for the quality and \\nscaling of AI systems. Structured \\nworkflows make it significantly easier to \\ndevelop and operate  \\nAI systems that meet the demands of \\ndeployers, regulators, and providers. \\nOrganisations can implement lifecycle \\nmanagement with MLOps in a very \\npractical way and thus create immediate \\nadded value for the scaling and quality assurance \\nof AI systems. Prerequisite: To do this, they must be able to draw on a combination of competen-\\ncies from the fields of AI development, software development, DevOps, and data technology/\\nscience. \\nThe specific challenges for high-risk AI providers are primarily to implement proven MLOps \\narchitectures for all their systems, to align specific principles, components, roles, and processes \\nwith the requirements of the EU AI Act and then to document them fully. An example of a necessary \\nextension is the control and test processes for individual case-specific quality assurance, which \\ncan be carried out at different points in the workflow. \\nThe storage and monitoring of meta, input and output data is also extremely valuable, as it enables \\nextended performance analyses and a higher degree o f traceability. This pays off in risk management \\nand AI liability and, together with the feedback loops in MLOps, represents an advantage for the \\ncontinuous and rapid improvement of AI systems that should not be underestimated.\\n9 Kreuzberger, Kühl und Hirschl (2022): Machine Learning Operations (MLOps): Overview, Definition, and ArchitectureDeployment\\nIterationDevelopment OperationsData\\nData\\nTest\\nTestPlan\\nning\\nTuning\\nM\\nodel\\nRetirementAda\\nption\\nMonitoringOperationIdea\\nMay 202416 | PwC | Trustworthy AIMay 2024Enablement of (end) users\\nThe EU AI Act explicitly requires users to be enabled to utilise the respective AI system.  \\nFurthermore, the EU AI Act obliges system providers to provide additional transparency to people \\nwho interact with the AI system and use its results. Analogous to the data protection notices and \\nconsent to the processing of cookies (“opt-in”) via so-called cookie banners, which many are now \\nfamiliar with from every website, AI banners and declarations could also help to implement these \\nrequirements and thus become widespread in the future. This is because natural persons need to \\nknow that they are interacting with an AI system, wh o is providing it (for any queries), what it does, \\nwhat its technical characteristics are (e.g., the level of performance), what is expected of users and \\nhow to interpret the system’s results. This, too, will ultimately have an impact on any liability issues. \\nHowever, the EU AI Act does not make any concrete specifications in this regard.\\nGetting these aspects right poses several linguisti c, technical, and economic challenges. To counterac t \\nfundamental uncertainties about AI systems among end users, the linguistic design must strike a \\nbalance between easy-to-understand language and concise texts and content that is technically \\nand legally sufficient. The technical and economic challenges lie in explaining the results. It is  \\nnot always easy to present the connection between an AI system’s input and output. There are \\nsolutions for so-called “explainable AI”, but here, too, the information must be adapted to the \\nexpected level of knowledge of the end user. On the other hand, the intellectual property of the  \\nAI provider must be protected accordingly, and no more than necessary must be revealed about \\nthe inner workings of an AI system.\\nConformity management\\nTo put high-risk systems into operation, onto the market or use their output in the EU market, \\nregulated organisations must not only achieve compl iance with the AI Act but be able to demonstrate \\nit. This means that based on comprehensive document ation of the individual governance components \\n(“technical documentation”), compliance must be ass essed. Depending on the use case, an internal \\ncontrol system or an external body authorised to assess conformity can be used. Subsequently, \\nthe compliant high-risk AI system must be labelled accordingly and registered in an EU database. \\nIn addition, an AI provider has an obligation towards the relevant authorities to demonstrate a \\ndeclaration of conformity and to provide access to data and documentation in case of justified \\nrequests. If a system is not compliant or there are incidents in operation, the relevant authorities \\nmust be informed and compliance restored.\\nMay 202417 | PwC | Trustworthy AI\\n17 | PwC | Trustworthy AIMay 20241st Line of DefenceUnits TasksData Scientists\\nMachine Learning  \\nDevelopers\\nMLOps Engineers\\nImplementation at  \\nuse case level\\nDocumentation2nd Line of Defence\\nLegal Department\\nCompliance Department\\nDefinition of legal  \\nrequirements\\nEstablishing controls\\nStandards and  \\nspecifications and  \\nBest Practices3rd Line of Defence\\nInternal Audit\\nExternal Audit\\nIndependent assessment  \\nof conformity with the  \\nEU AI ActThe path to compliance with the EU AI Act is a team effort. Important contributions must be made \\nalong a wide range of functions and roles. \\nWhile compliance departments are often responsible for laying out the requirements for documenting \\nsystems, the teams providing technical support for the AI system must prepare and regularly update \\nthe documentation. The definition of control sets a lso usually falls within the scope of the so-called  \\nSecond Line of Defence. However, technical and func tional teams provide evidence of compliance \\nwith the controls. Internal departments or external  notified bodies, which have an independent view \\nof the evidence and the controls, then carry out th e final evaluation.\\nOne organisational challenge is to distribute respo nsibility optimally. The goal: a truthful and posit ive \\nconformity assessment must be carried out, and obli gations must be fulfilled. Although documentation \\ntasks are often postponed, organisations should not  avoid preparing the documents early on and in a \\ndisciplined manner because ex-post preparation is, in any  \\ncase, more time-consuming and, in some cases,  \\neven impossible. So-called model maps, data  \\nsheets and other technical system information  \\noffer added value that goes beyond regulatory  \\ncompliance. In our experience, this also  \\nsimplifies the consolidation of best  \\npractices in the development process  \\nand the transition to scaled operations.\\nMay 202418 | PwC | Trustworthy AIThe EU AI Act will have a massive impact on the dev elopment, \\nuse and commercialisation of AI systems in the comi ng years. \\nUK businesses along the entire AI value chain must act now. \\nEarly implementation of holistic AI governance and compliance \\nmanagement systems gives organisations not only a time \\nadvantage over the competition but also an immediat e economic \\nadvantage through shortened time-to-market and high quality  \\nof their high-risk AI systems. The requirements are complex and'),\n",
       " Document(page_content='use and commercialisation of AI systems in the comi ng years. \\nUK businesses along the entire AI value chain must act now. \\nEarly implementation of holistic AI governance and compliance \\nmanagement systems gives organisations not only a time \\nadvantage over the competition but also an immediat e economic \\nadvantage through shortened time-to-market and high quality  \\nof their high-risk AI systems. The requirements are complex and \\npresent companies with new kinds of challenges that will take \\ntime to overcome.\\nAdditionally, the expected shortage of AI (governan ce) experts in \\nthe transitional period will likely become a signif icant cost driver. \\nOrganisations with high-risk use cases that do not want to wait \\nseveral years to benefit from using AI systems in r egulated areas \\nshould, therefore, seize their opportunity now. If,  in addition, it  \\nis possible to utilise as many synergies as possibl e with existing \\ncompliance structures and fall back on best practices for \\nmachine learning operations, organisations can buil d up the \\ndesired AI governance and compliance quickly and ef ficiently.\\nCompanies and public organisations in the UK can se t the \\ncourse now to shape their digital transformation su ccessfully \\nwith the use of AI. The ability to combine quality,  compliance and \\nscaling of AI systems will significantly determine the success of  \\norganisations in the market. Linking these aspects requires \\ninterdisciplinary competencies in organisations alo ng the entire \\nAI value chain. This is how to create structures an d processes \\nfor an AI governance that is technically, legally, and \\norganisationally fit for the future.The key next steps you should be taking include:\\n• Identify all Al systems in your organisation and th eir status, \\nwhich will form the basis for decisions in establis hing \\nappropriate Al governance.\\n• Classify the AI systems into risk tiers and impact assess it \\nagainst requirements of the EU Al Act, to help bett er assess \\nthe implications of the Al regulation on your organ isation.  \\nIn addition to the Al Act, other (forthcoming) hori zontal and \\nsectoral regulations should also be considered, inc luding  \\nany future AI legislation in the UK.\\n• Assess the potential gaps and develop an execution plan to \\nbridge this, ensuring that appropriate accountabili ty and \\ngovernance is established when the AI Act comes int o force.\\n• Implement employee training and increase AI awarene ss. \\nEducate staff about the AI Act and its impact on th eir roles. \\nThis is essential to fulfill human oversight requir ements, but \\nalso other key requirements such as robustness test ing.  \\nDoing so will demonstrate that you are proactively managing \\nthe risks associated with AI in your operations.4.\\nConclusion and outlook19 | PwC | Trustworthy AI\\nMay 2024This publication has been prepared for general guidance on matters of interest only, and does not constitute professional \\nadvice. You should not act upon the information contained in this publication without obtaining specific professional advice. \\nNo representation or warranty (express or implied) is given as to the accuracy or completeness of the information contained in \\nthis publication, and, to the extent permitted by law, PricewaterhouseCoopers LLP , its members, employees and agents do not \\naccept or assume any liability, responsibility or duty of care for any consequences of you or anyone else acting, or refraining to \\nact, in reliance on the information contained in this publication or for any decision based on it.\\n© 2024 PricewaterhouseCoopers LLP . All rights reserved. ‘PwC’ refers to the UK member firm, and may sometimes refer to the \\nPwC network. Each member firm is a separate legal entity. Please see www.pwc.com/structure for further details.\\nRITM16580253Your contacts\\nLeigh Bates \\nPartner\\nUK Risk AI Leader\\n+44 7711 562 381\\nleigh.bates@pwc.comFabrice Ciais \\nDirector\\nAI Governance and Validation\\n+44 7843 334 241\\nfabrice.ciais@pwc.comChris Oxborough\\nPartner\\nUK Responsible AI Leader\\n+44 7818 510 537\\nchris.oxborough@pwc.com\\nTrishia Ani \\nManager\\nData and Artificial Intelligence\\n+44 7818 636970\\ntrishia.ani@pwc.com\\nEU AI Act Governance: \\nHendrik Reese \\nPartner\\nResponsible AI\\n+49 151 70423201\\nhendrik.reese@pwc.comBanking sector: \\nKonstantin Dagianis\\nPartner\\nFinancial Services (Banks)\\n+49 171 9770067\\nkonstantinos.dagianis@pwc.comEU AI Act Legal: \\nDr. Jan-Peter Ohrtmann\\nPartner\\nData Protection\\n+49 171 7614597\\njan-peter.ohrtmann@pwc.comInsurance sector:  \\nDavid Richter\\nPartner\\nFinancial Services \\n(Insurances)\\n+49 1511 0578093\\ndavid.richter@pwc.com')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document number 1 has 2132 tokens\n",
      "Document number 2 has 2073 tokens\n",
      "Document number 3 has 1971 tokens\n",
      "Document number 4 has 1957 tokens\n",
      "Document number 5 has 1979 tokens\n",
      "Document number 6 has 1050 tokens\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(docs)):\n",
    "    print(f\"Document number {i+1} has {llm.get_num_tokens(docs[i].page_content)} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_chain = load_summarize_chain(llm=llm, chain_type='map_reduce',verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/talib/anaconda3/envs/tf_env/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"Implementing the EU AI Act in the UK as a value driverTrustworthy AIMay 2024Artificial intelligence (AI) is a key technology for digital  \n",
      "transformation in private and public organisations. By 2030,  \n",
      "we expect that AI will be a direct or indirect comp onent in all \n",
      "processes and products along the entire value chain . From smart \n",
      "washing machines to (partially) autonomous vehicles , from \n",
      "automated application processing to intelligent cha tbots, and \n",
      "from optimised maintenance processes to production robots – \n",
      "the rapid spread of AI can be seen all around. \n",
      "In addition to the economic relevance of use cases,  trust in the \n",
      "performance, security, reliability, and fairness of  AI is an essential \n",
      "factor in deciding for or against the use of AI sys tems. Both \n",
      "dimensions are inextricably linked because, in prac tice, economic \n",
      "efficiency and trustworthiness are mutually depende nt on the  \n",
      "use of AI. Finally, the use of the technology requi res certainty  \n",
      "and trust on the part of users, customers, and deci sion-makers, \n",
      "which only sound governance based on best practices  and \n",
      "generally accepted standards can provide.\n",
      "For this reason, the institutions of the European Union  \n",
      "have developed and launched harmonised regulations  \n",
      "for AI systems. This comprehensive “EU AI Act” is directly \n",
      "applicable in the member states and affects both private  \n",
      "and public organisations – regardless of whether they are \n",
      "providers or deployers of an AI system. Though regulated in  \n",
      "the EU, it's important to note the regulation's  extra-territorial \n",
      "extent. The EU AI Act will have a tangible impact on UK \n",
      "businesses if they provide AI systems on the EU market,  \n",
      "deploy AI systems in the EU, or provide and deploy AI  \n",
      "Wsystems elsewhere if the output is used in the EU. The regulation aims both to promote European AI val ue creation \n",
      "through uniform standards and to protect EU citizen s. The EU AI \n",
      "Act is the first comprehensive law that aims to set  a global \n",
      "standard with regards to holistic AI governance, pr omoting the \n",
      "development and use of high-quality AI systems and making the \n",
      "risks of AI systems manageable and transparent thro ughout the \n",
      "entire lifecycle. Given its global importance, orga nisations should \n",
      "prioritise aligning with the regulation in order to  gain a strong first \n",
      "mover advantage by balancing their legally complian t \n",
      "implementation of the requirements in and around AI  systems \n",
      "case-by-case at an early stage. Otherwise, those af fected expose \n",
      "themselves to many legal risks, these include not o nly potential \n",
      "fines under the EU AI Act, but also fines under the  GDPR,  \n",
      "and industry-specific regulations, or also liabilit y claims if they \n",
      "use a defective AI system.\n",
      "However, implementing diverse regulations not only poses \n",
      "challenges for organisations but also opens opportu nities for \n",
      "them to improve their AI in terms of quality. This is all the more \n",
      "true because the increasing use of AI puts the resp onsible \n",
      "handling of data more strongly than ever before in the focus  \n",
      "of Corporate Social Responsibility – companies‘ res ponsibility  \n",
      "for the environment and society. With the right app roach and  \n",
      "the corresponding interdisciplinary competencies in  AI \n",
      "governance and law, organisations can avoid efforts  and risks, \n",
      "shorten (market) introduction times for their AI sy stems and take \n",
      "a pioneering role in digital transformation with AI .Foreword2 | PwC | Trustworthy AIMay 2024Scaling\n",
      "AI systems are finding broader and more intensive a pplications \n",
      "and are thus increasingly becoming a core component  of global \n",
      "value creation. PwC 27th UK CEO Survey1. This is also imperative \n",
      "because AI systems generate the greatest added valu e when \n",
      "they are applied on a large scale and quickly move beyond the \n",
      "pilot phase. Economies of scale take on a central r ole in AI \n",
      "projects because high fixed costs in development me et low \n",
      "marginal costs in operation.\n",
      "1 PwC 27th UK CEO Survey\n",
      "2 Politico “Dutch scandal serves as a warning for Europe over risks of using algorithms” 2022However, there is often a lack of adequate AI governance \n",
      "systems to operationalise and subsequently scale AI-enabled \n",
      "solutions. Without them, operating the system becomes a risk \n",
      "to an organisation’s reputation and profitability. In addition, the \n",
      "use of AI without adequate monitoring and governance systems \n",
      "can have a tangible negative impact on the quality of life of \n",
      "many people in a critical situation, as the child benefit scandal \n",
      "in the Netherlands showed, where migrants were discriminated \n",
      "against for years by an algorithm.2\n",
      "Nevertheless, Around 52% of CEOs point to a lack of skills in \n",
      "the workforce as a key challenge in implementing AI1. Under \n",
      "these circumstances, there are immense challenges in  making  \n",
      "AI systems safe, robust, fair, and effective.The synergy potential  \n",
      "of scaling and regulation\n",
      "1.3 | PwC | Trustworthy AIMay 2024Regulation\n",
      "The EU AI Act imposes several far-reaching requirem ents on many \n",
      "AI systems. The regulation is expected to have a si milar impact on \n",
      "the affected AI systems as, for example, the Genera l Data  \n",
      "Protection Regulation (GDPR) had on the processing of  \n",
      "personal data.\n",
      "In addition to the general regulation of AI by the EU AI Act, other \n",
      "requirements are relevant to AI use cases: Horizont al ones, such \n",
      "as the GDPR or the EU Data Act, and vertical or sec toral ones, \n",
      "such as the UK Automated Vehicles Bill.\n",
      "Already today, 64% of CEOs cite the regulatory envi ronment  \n",
      "as barrier to implementing AI systems1 – a proportion that will \n",
      "increase significantly with the entry of the EU AI Act into force.  \n",
      "To ensure that AI governance can address the multip le legal and  \n",
      "technical aspects, aligning it with the regulatory framework early \n",
      "on is crucial. Failures are difficult to correct in  retrospect and can \n",
      "lead to unintended liability risks, increased costs , or inefficient \n",
      "allocation of resources in AI development.Building bridges between scaling and regulation\n",
      "So are organisations only implementing AI governance for \n",
      "compliance reasons? In our experience, it is an opportunity to \n",
      "manage and improve AI transformation. A closer look  at the EU \n",
      "AI Act reveals a great deal of overlap between the requirements \n",
      "set in regulation and the structures necessary for operationalising \n",
      "and scaling AI systems. Conformity assessments and specific \n",
      "documentation requirements are, of course, primarily relevant \n",
      "from a compliance perspective. However, flexible da ta, risk, and \n",
      "lifecycle management systems, especially, are indispensable to \n",
      "enable organisations to successfully transition their AI systems \n",
      "from the pilot phase to scaled operations.\n",
      "Selection of relevant legal norms for the use of AI\n",
      "Development and \n",
      "operation of AI systems \n",
      "in the EUEU AI ACT\n",
      "Access to data by (end) \n",
      "users or third partiesEU DATA ACT\n",
      "OTHER  \n",
      "REGULATIONSSensitive data  \n",
      "for model training \n",
      "and explainabilityGDPR\n",
      "Vehicles with autonomous \n",
      "driving functionUK Automated \n",
      "Vehicles Bill\n",
      "1 PwC 27th UK CEO Survey4 | PwC | Trustworthy AIMay 20242.\n",
      "Quo vadis EU AI Act?\n",
      "The EU AI Act is a regulation of the European Union  to define harmonised regulations for systems with artificial intelligence.  \n",
      "The term “AI system” is very broadly defined in the  EU AI Act:The EU AI Act and  \n",
      "its implications\n",
      "“AI system” means a machine-based system designed t o operate with varying levels of autonomy, that may  exhibit adaptiveness \n",
      "after deployment and that, for explicit or implicit  objectives, infers, from the input it receives, ho w to generate outputs such as \n",
      "predictions, content, recommendations, or decisions  that can influence physical or virtual environment s.6\n",
      "The EU Commission's original proposal for the regul ation of  \n",
      "AI systems was published in April 2021 and was revi sed and \n",
      "amended several times during the legislative proces s before \n",
      "finally being adopted in 2024. After the EU AI Act comes into \n",
      "force, transitional periods are provided for until it takes effect, \n",
      "within which organisations must implement the requi rements. \n",
      "The deadlines are (with minor deviations) 6 months for prohibited \n",
      "AI systems, 12 months for general purpose AI (GPAI)  systems, \n",
      "24 months for high-risk AI systems in accordance wi th Annex \n",
      "III and finally up to 36 months for high-risk AI sy stems in \n",
      "accordance with Annex I. After this period, non-com pliance \n",
      "could result in significant fines of up to 35 milli on euros or  \n",
      "7% of the previous year's global turnover for compa nies that \n",
      "fail to comply with the prohibitions and 15 million  euros or 3% \n",
      "of the previous year's global turnover for companie s that fail to \n",
      "comply with the rules for high-risk or GPAI systems .3\n",
      "The impact of the EU AI Act on private and public organisations \n",
      "is complex and must be determined on a case-by-case basis.  \n",
      "In the following sections, we therefore take a look at the three \n",
      "essential aspects of the regulation: the role of regulated  \n",
      "organisations, the risk classification of AI system s and the \n",
      "requirements for high-risk AI systems and GPAI systems. We \n",
      "also look at the challenges involved in practical implementation \n",
      "and conclude by outlining a solution.What does this mean for UK businesses?\n",
      "The AI Act sets out specific requirements for ‘providers’ and \n",
      "‘deployers’ of AI systems and businesses affected will fall into \n",
      "three domains:\n",
      "• Providers are those who develop AI systems and “have an AI \n",
      "system developed with a view to placing it on the market or \n",
      "putting it into service under its own name or trademark, \n",
      "whether for payment or free of charge”. An example of a \n",
      "provider is OpenAI, where they develop base foundation \n",
      "models. The scope is those AI systems established within the \n",
      "EU or in a third country placing AI systems on the EU market.\n",
      "• Users (‘deployers’) are “any natural or legal person, public \n",
      "authority, agency or other body using an AI system under its \n",
      "authority”. Those using AI systems in the context of personal \n",
      "or non-professional activity are exempt from the\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"whether for payment or free of charge”. An example of a \n",
      "provider is OpenAI, where they develop base foundation \n",
      "models. The scope is those AI systems established within the \n",
      "EU or in a third country placing AI systems on the EU market.\n",
      "• Users (‘deployers’) are “any natural or legal person, public \n",
      "authority, agency or other body using an AI system under its \n",
      "authority”. Those using AI systems in the context of personal \n",
      "or non-professional activity are exempt from the \n",
      "requirements. A deployer could be a business that uses  \n",
      "a provider’s API to embed AI within their own products, \n",
      "fine-tunes a foundation model to develop a specialised \n",
      "product, or may simply use AI systems as internal tools.\n",
      "• Providers and Users (‘deployers’) of AI systems located in  \n",
      "a third country, where the output produced by the AI systems \n",
      "is intended to be used in the EU.\n",
      "3 Current version of the AI regulation as of 13 March 20245 | PwC | Trustworthy AIMay 2024\n",
      "Example 1:\n",
      "A company or public body changes the intended purpose \n",
      "of an AI system already placed on the market or put into \n",
      "operation by a third party, which does not pose a high risk, \n",
      "in such a way that the modified AI system becomes a \n",
      "high-risk AI system.Example 2:\n",
      "A distributor who considers or has reason to believe that a \n",
      "third-party high-risk AI system that it has made available \n",
      "on the market does not comply with the requirements of \n",
      "the EU AI Act shall take necessary measures to bring that \n",
      "system into compliance, withdraw or recall it, or ensure \n",
      "that the supplier, the importer or any other relevant actor, \n",
      "as appropriate, takes appropriate corrective action.Addressees in the AI value chain \n",
      "At the centre of the regulation are the deployers and providers \n",
      "of AI systems. They bear the main burden of the requirements. \n",
      "On the one hand, these are providers who place regulated  \n",
      "AI systems on the market or put them into operation in the \n",
      "European Union, regardless of whether these providers are \n",
      "established in the EU or in a third country, as well as deployers \n",
      "of regulated AI systems who are established in the European \n",
      "Union. In addition, it also applies to providers and deployers  \n",
      "of regulated AI systems established or resident in a third \n",
      "country if the result produced by the system is used in the \n",
      "European Union. The EU AI Act thus has an extraterr itorial \n",
      "application and also indirectly regulates beyond the borders  \n",
      "of the European Union and the European Economic Area.\n",
      "Under certain circumstances, the EU AI Act also places other \n",
      "actors, such as importers, distributors or manufacturers of \n",
      "high-risk AI systems, on an equal footing with prov iders in  \n",
      "terms of their obligations (see example 1).\n",
      "At the same time, the deployers, representatives of  the providers \n",
      "(so-called authorised representatives), importers a nd distributors \n",
      "of high-risk AI systems are required to ensure the extensive  \n",
      "obligations of the providers – insofar as this is t heir responsibility \n",
      "(see example 2). \n",
      " \n",
      "In order to ensure compliance with the requirements of the  \n",
      "EU AI Act across the entire value chain, the obligations of \n",
      "deployers of high-risk AI systems apply alongside the \n",
      "requirements of other stakeholders. Deployers, i.e. natural or \n",
      "legal persons, including public authorities, institutions or other \n",
      "bodies under whose responsibility the system is used, are \n",
      "obliged, among other things, to ensure human oversight and \n",
      "must ensure that input data is subject to the specifi ed purpose  \n",
      "of the high-risk AI system.\n",
      "In fact, the involvement of the various stakeholders means that \n",
      "every organisation dealing with AI systems must define and \n",
      "continuously review its own role in order to fulfil its obligations \n",
      "correctly. Furthermore, this involvement means that purchasers \n",
      "of AI systems in particular should optimise their legal position \n",
      "vis-à-vis manufacturers, providers and distributors. For \n",
      "example, drafting a contract under IT law offers the opportunity \n",
      "to ensure specific performance obligations, such as support \n",
      "and maintenance in particular, to ensure the suitability of the AI \n",
      "system for use within the scope of the EU AI Act under warranty \n",
      "for defects law and to enable recourse under liability law.\n",
      "May 20246 | PwC | Trustworthy AIAI systems with unacceptable risks  are prohibited per se. \n",
      "These include, for example, systems for the subliminal  \n",
      "manipulation of people or certain biometric real-time \n",
      "recognition systems in public spaces.  \n",
      "High-risk AI systems  are at the centre of the regulation. These \n",
      "are permitted, but in order to develop and use them, they must comply with comprehensive documentation, monitoring and \n",
      "quality requirements. The group of high-risk AI systems \n",
      "comprises use cases defined by the Commission, some of \n",
      "which are sector-specific and presented on the next page.Classification of AI systems \n",
      "The EU AI Act divides AI systems into several categories based \n",
      "on their risk characteristics, which are either permitted without \n",
      "restriction, permitted under certain conditions or prohibited.  This approach is based on an assessment of the expected  \n",
      "risks that a particular AI system may pose to the health, safety \n",
      "or fundamental rights of EU citizens.\n",
      "Minimal-risk AI systemsHigh-risk AI system requirements\n",
      "AI systems with additional transparency requirementsGPAI system requirements\n",
      "•    Risk management system\n",
      "•    Data governance\n",
      "•    Technical documentation\n",
      "•    Record-keeping\n",
      "•    Transparency obligations\n",
      "•    Human oversight\n",
      "•    Accuracy\n",
      "•    Robustness and cyber securityAll GPAI (General Purpose AI)\n",
      "•  Technical documentation, instructions for use, \n",
      "Compliance with the Copyright Directive \n",
      "and publication of a summary of the training \n",
      "content\n",
      "GPAI with systemic risks\n",
      "•  Model evaluation, tracking, documenting and \n",
      "reporting about serious incidents, cyber securityProhibited AI systems\n",
      "May 2024\n",
      "May 20247 | PwC | Trustworthy AIMay 2024AI systems with a general purpose of use (GPAI) were most \n",
      "recently included in the regulation. Providers of G PAI systems4 \n",
      "must create technical documentation, provide instru ctions for \n",
      "use, draw up guidelines for compliance with EU copy right law \n",
      "and publish a summary of the content used for train ing. Providers \n",
      "of GPAI systems that pose a systemic risk should al so carry out \n",
      "standardised model evaluations such as adversarial testing, \n",
      "mitigate systemic risks, track and report serious i ncidents and \n",
      "ensure cybersecurity protection.\n",
      "Deployers and providers of certain AI systems with a direct or \n",
      "indirect impact on human end users are also subject  to increased \n",
      "transparency obligations . This includes systems that are \n",
      "designed to interact with people or expose natural persons  \n",
      "to biometric categorisation, for example. Certain s ystems that  \n",
      "4 Some providers of GPAI systems with a free and open license and without systemic risks are partially excluded.are used to generate or manipulate images, video, s ound or text \n",
      "are also affected. Deployers and providers are obli ged to ensure \n",
      "the transparency of these AI systems towards end us ers in future.\n",
      "AI systems that do not fall into any of the aforeme ntioned risk \n",
      "categories are considered to have a minimal risk . They are \n",
      "permitted without additional requirements. However,  the EU \n",
      "Commission is authorised to adapt the list of regul ated AI \n",
      "systems and add further use cases.High-risk AI systems according to Annex I\n",
      "High-risk AI systems according to Annex III\n",
      "•  Biometric systems\n",
      "• Critical infrastructure\n",
      "• Education\n",
      "• Human Resources•   Essential private and public  \n",
      "services, including finance  \n",
      "and insurance\n",
      "• Law enforcement• Migration, asylum and border controls\n",
      "•  Administration of justice and  \n",
      "democratic processesSection A –  High-risk AI systems for which flexibility in the implementation of compliance is granted to avoid double \n",
      "regulatory burden:\n",
      "• Machines \n",
      "• Toy safety\n",
      "•  Recreational craft and personal \n",
      "watercraft\n",
      "• Lifts and safety components for lifts•  Equipment and protective systems  \n",
      "in potentially explosive atmospheres\n",
      "• Radio equipment\n",
      "• Pressure equipment\n",
      "• Ropeways • Personal protective equipment \n",
      "•  Appliances for burning gaseous fuels\n",
      "• Medical devices\n",
      "• In-vitro diagnostics\n",
      "Section B –  High-risk AI systems that are regulated by sector but exempt from most requirements:\n",
      "• Civil aviation security \n",
      "• Two-, three- and four-wheeled vehicles\n",
      "•  Agricultural and forestry vehicles •  Motor vehicles and motor vehicle \n",
      "trailers as well as systems, components \n",
      "and separate technical units for  \n",
      "these vehicles• Marine equipment \n",
      "• Interoperability of the railway systemHigh-risk AI systems according to Annex I and III\n",
      "May 20248 | PwC | Trustworthy AI\n",
      "8 | PwC | Trustworthy AI9 | PwC | Trustworthy AI\n",
      "Challenges of a legally compliant risk classification \n",
      "The correct, i.e., legally compliant, allocation of  AI systems to  \n",
      "one of the risk categories of the EU AI Act is a de cisive factor in \n",
      "avoiding the threat of massive fines due to missing  or insufficient \n",
      "compliance. In addition to its role in AI value cre ation, it also plays \n",
      "a key role in defining the requirements that must b e met by the \n",
      "organisation and the AI system in accordance with t he EU AI Act.\n",
      "However, one example illustrates that it can be cha llenging for \n",
      "organisations to classify use cases in a legally co mpliant way:  \n",
      "In the face of advancing digitalisation, employers are increasingly \n",
      "opting to use systems that enable targeted advertis ing and \n",
      "efficient recruitment of qualified employees. Given  the broad \n",
      "definition of AI systems in the EU AI Act as well a s the definition \n",
      "for classifying use cases in the application and se lection process \n",
      "as high-risk AI systems, the following question wil l arise in the \n",
      "future: Is the use of supporting software in these areas already \n",
      "subject to the comprehensive requirements of the EU  AI Act? \n",
      "The EU AI Act itself does not provide for a concretisation  \n",
      "of this definition. Rather, it will be important – following\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"definition of AI systems in the EU AI Act as well a s the definition \n",
      "for classifying use cases in the application and se lection process \n",
      "as high-risk AI systems, the following question wil l arise in the \n",
      "future: Is the use of supporting software in these areas already \n",
      "subject to the comprehensive requirements of the EU  AI Act? \n",
      "The EU AI Act itself does not provide for a concretisation  \n",
      "of this definition. Rather, it will be important – following  \n",
      "the case law of the European Court of Justice (ECJ) – to \n",
      "determine the classification into risk categories per the  \n",
      "purpose and recitals of the legislator, relevant case law,  \n",
      "and recognised methods of inter-pretation to enable a  \n",
      "selective and judicially robust classification.\n",
      "Legally compliant risk classification is relevant n ot only in the \n",
      "context of the EU AI Act but also because of the pr oposal for  \n",
      "the EU AI Liability Directive published in Septembe r 2022. This \n",
      "regulates the liability of deployers, distributors and manufacturers \n",
      "for damage caused by AI systems and takes up the ri sk levels of \n",
      "the EU AI Act. The classification thus also has con sequences for \n",
      "the assessment of liability risks. Those who miscla ssify AI systems \n",
      "must consequently expect both fines and civil liabi lity in the event \n",
      "of missing or unreliable AI governance and document ation.AI Liability Directive\n",
      "The proposal to harmonise liability rules for damage \n",
      "caused by the use of artificial intelligence builds  \n",
      "on the definitions established in the EU AI Act. The \n",
      "Commission assumes that the proof of damage caused \n",
      "by the breach of a statutory duty is partly impossible  \n",
      "or, at any rate, associated with considerable difficulties \n",
      "for injured parties of AI systems. To counteract this,  \n",
      "the EU AI Liability Directive provides that causality \n",
      "should be presumed under certain conditions. In \n",
      "particular, the risk classification under the EU AI Act \n",
      "plays a role. A right of access to information and,  \n",
      "thus, evidence in cases involving high-risk AI systems \n",
      "flanks the facilitation of proof of causality.\n",
      "May 2024May 2024Requirements for high-risk AI systems \n",
      "The EU AI Act requirements for high-risk AI systems are \n",
      "extensive and pose complex challenges for organisations. The \n",
      "following overview shows the key requirement areas for high-risk  \n",
      "AI systems under the EU AI Act:\n",
      "Due to the heterogeneity of AI systems, the requirements  \n",
      "in the EU AI Act have been deliberately formulated in a  \n",
      "general and abstract manner by the European legislator.  \n",
      "The major challenge in practice is to operationalise these \n",
      "requirements so that they can be seamlessly integrated into \n",
      "technical and organisational processes and, at the same time, \n",
      "provide legal certainty. \n",
      "To implement the regulation in an innovation-friendly and \n",
      "efficient manner, the requirements should be integrated  \n",
      "or merged as far as possible into existing processes and \n",
      "structures, such as IT compliance systems. If this is not  \n",
      "done, redundant structures and processes will increase \n",
      "personnel and IT-related expenses. Moreover, there is a  \n",
      "risk of inconsistencies in assess-ment and documentation,  \n",
      "and acceptance of compliance with the legal requirements  \n",
      "in IT and operational business units will decline.\n",
      "An example of an overlap between existing compliance \n",
      "processes and the future regulations of the EU AI Act is  \n",
      "the assessment of risks: While the EU AI Act requires an \n",
      "assessment of expected risks to health, safety, or  \n",
      "fundamental rights, the GDPR requires a “data protection \n",
      "impact assessment” in the event of expected high risks  \n",
      "to the rights and freedoms of data subjects. From a corporate social governance perspective, a data ethics \n",
      "risk assessment may also need to be added to address whether \n",
      "such processing is warranted. All these legal risk assessments \n",
      "should be bundled into one process, embedded in a – possibly \n",
      "overarching – compliance management system and subject to a \n",
      "technical assessment with a consistent benchmark. This allows \n",
      "existing processes and documentation to be used and aligned \n",
      "with each other, thus avoiding risks of incongruence associated \n",
      "with compliance and creating efficiency.\n",
      "There is also more work to be done by the EU institutions in  \n",
      "the context of standardisation if they want to create regulation \n",
      "that promotes innovation as promised. At the level of a concrete \n",
      "AI use case, the reality of AI systems and regulatory ideas can \n",
      "quickly diverge. For human oversight, for example, the EU  \n",
      "AI Act stipulates that it takes at least two people to verify the \n",
      "results of biometric identification with AI systems. However, \n",
      "whether humans are actually able to improve monitoring and \n",
      "decision-making in the relevant fields of application is \n",
      "questionable. Therefore, the specifications work against \n",
      "automation and efficiency enhancement by AI systems  \n",
      "in such cases.Resource Management  \n",
      "Allocation, \n",
      "Roles & Rights, \n",
      "Capacity, \n",
      "Accountability\n",
      "Transparency  \n",
      "Requirements, \n",
      "Information, \n",
      "Instructions, \n",
      "ExplainabilityRisk Management  \n",
      "Identification, \n",
      "Assessment, \n",
      "Prevention & Mitigation, \n",
      "Monitoring\n",
      "Documentation  \n",
      "Model Cards, \n",
      "Data Sheets, \n",
      "System Information, \n",
      "RetentionData Management  \n",
      "Quality Assessment, \n",
      "Annotation,  \n",
      "Changes, Logging, \n",
      "Data Splits, Data Protection\n",
      "Conformity Assessment  \n",
      "Audit,  \n",
      "Declaration, \n",
      "CE Marking, \n",
      "AdjustmentsLifecycle Management  \n",
      "Development & Operation, \n",
      "Performance, Tests,  \n",
      "Robustness, Monitoring & \n",
      "Oversight, (Cyber) Security\n",
      "Interaction with Authorities  \n",
      "Registration, \n",
      "Communication, \n",
      "Access, \n",
      "Reporting\n",
      "Challenges in implementing functional AI governance along the lines of the EU AI Act\n",
      "May 202410 | PwC | Trustworthy AI10 | PwC | Trustworthy AIMay 2024\n",
      "Combining high-quality AI systems and AI compliance is the  \n",
      "key to scaling and, thus, to the success of sustainable value \n",
      "creation with AI systems. Both aspects require recognised \n",
      "standards, best practices, and appropriate tools. The goal: fast, \n",
      "secure, and efficient development and operation of AI systems.In the following, we want to outline an AI complian ce management \n",
      "system that can be used step-by-step to build up organisation-\n",
      "specific AI governance that combines both aspects. To this end, \n",
      "we draw on concepts and principles from existing compliance \n",
      "management systems, which we blend with our experience and \n",
      "the requirements of the EU AI Act.Holistic AI governance for \n",
      "compliance and quality3.\n",
      "1. Culture \n",
      "•  Definition of a set of values for acting with \n",
      "integrity and in compliance with the rules\n",
      "•  Consideration of legal, economic and  \n",
      "technical aspects\n",
      "•  Involvement and motivation of employeesCornerstones of compliance management systems\n",
      "2. Goals and risks \n",
      "•   Derivation of minimum requirements from \n",
      "corporate goals and strategy\n",
      "•  Systematic risk analysis for the identification \n",
      "and assessment of risk\n",
      "•  Prioritisation of business areas and  \n",
      "implementation measures\n",
      "6. Monitoring and  \n",
      "improvement \n",
      "•  Implementation of intelligent \n",
      "monitoring mechanisms\n",
      "•  Identification of improvement \n",
      "potentials and errors throughout \n",
      "the lifecycle\n",
      "•  Regular checks and tests as well \n",
      "as audits to verify conformity3. Coordination \n",
      "•  Definition and assignment  \n",
      "of responsibilities\n",
      "•  Design of reporting,  \n",
      "decision-making and escalation \n",
      "channels\n",
      "•  Linkage and coordination with \n",
      "other management systems\n",
      "5. Communication and training \n",
      "•  Communicating the defined value framework\n",
      "•  Technical and legal training of employees\n",
      "•  Increasing awareness by communicating \n",
      "compliance measures and their effects4. Programme \n",
      "•  Implementation of prevention and \n",
      "mitigation measures for risk\n",
      "•  Orientation towards best practices and \n",
      "recognised standards\n",
      "•  Design and development guides taking \n",
      "into account the lifecycle-specific aspects \n",
      "of AI systems1 2\n",
      "4 56 311 | PwC | Trustworthy AIEssential preparation \n",
      "Firstly, for any organisation that develops, operates, uses, \n",
      "imports, or distributes AI systems, it is important to prepare \n",
      "the setup of necessary compliance and governance \n",
      "components and develop a clear picture of the measures \n",
      "required for its use cases.\n",
      "Qualification & value orientation  \n",
      "Fundamental to successful AI governance is not only  \n",
      "the development and documentation of new processes  \n",
      "and structures but also their actual implementation by  \n",
      "qualified people.\n",
      "As explained above, a lack of know-how is one of the biggest \n",
      "barriers to digital transformation. Training concepts that \n",
      "establish a common knowledge and value base concerning \n",
      "artificial intelligence among all stakeholders and achieve buy-in \n",
      "for the AI-induced transformation offer a remedy here. \n",
      "In addition to the content imparted to participants, a continuous \n",
      "exchange between stakeholders is particularly important. \n",
      "Especially between departments that are far removed regarding \n",
      "responsibilities, such as technical AI development and the legal \n",
      "department, suitable workshops can help build bridges in terms \n",
      "of knowledge and generate targeted interactions for the \n",
      "permanent involvement of the respective persons. Based on \n",
      "cross-functional training, it is easier to find formats later in AI \n",
      "projects where different stakeholders jointly advance the \n",
      "development, operationalisation, and control of the AI systems.\n",
      "Impact assessment\n",
      "Identifying all AI projects in an organisation and their status \n",
      "(e.g., planning, development, and operation) forms the basis for \n",
      "all further decisions in establishing appropriate AI governance.  \n",
      "If organisations have subsequently classified risks and assigned \n",
      "roles according to the requirements of the EU AI Act, an impact \n",
      "assessment for individual AI use cases can help better assess \n",
      "the impact of AI regulation on the organisation. In addition to \n",
      "the EU AI Act, other horizontal and sectoral regulations should \n",
      "also be considered.Gap assessment \n",
      "Carrying out a comparison of the existing structures and \n",
      "processes with the previously identified compliance \n",
      "requirements makes it possible to determine concrete work\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"roles according to the requirements of the EU AI Act, an impact \n",
      "assessment for individual AI use cases can help better assess \n",
      "the impact of AI regulation on the organisation. In addition to \n",
      "the EU AI Act, other horizontal and sectoral regulations should \n",
      "also be considered.Gap assessment \n",
      "Carrying out a comparison of the existing structures and \n",
      "processes with the previously identified compliance \n",
      "requirements makes it possible to determine concrete work \n",
      "packages. A gap assessment also helps to identify overlaps \n",
      "from different regulations and plan a uniform implementation. \n",
      "Experience shows that many existing structures and processes \n",
      "can be expanded to include AI-specific measures, such as risk \n",
      "management, data management or cyber security.\n",
      "Compliance strategy \n",
      "The final step of the preparation is defining a compliance \n",
      "strategy to establish a holistic AI governance and compliance \n",
      "management system. This includes a list of concrete measures \n",
      "for establishing AI governance and closing previously identified \n",
      "gaps, the associated efforts, and a corresponding prioritisation. \n",
      "The prioritisation, on the one hand, results from the \n",
      "organisation-specific goals in terms of compliance, quality, and \n",
      "scaling the identified AI systems and, on the other hand, from a \n",
      "risk/impact analysis to define which regulations and business \n",
      "areas should be focused on first. This also marks the beginning \n",
      "of the implementation of the requirements of the EU AI Act.Example:  An organisation can align its AI governance  \n",
      "with existing IT governance processes and integrate it  \n",
      "into these. Use case management can be derived from  \n",
      "IT demand and portfolio management. In turn, requirements \n",
      "for high-risk AI systems can be integrated into the software \n",
      "development lifecycle. Of course, AI specifics must be taken \n",
      "into account here.12 | PwC | Trustworthy AI\n",
      "May 202413 | PwC | Trustworthy AI\n",
      "Modules of holistic AI governance\n",
      "Meeting all the requirements of the EU AI Act and other \n",
      "regulations is an undertaking that should not be un derestimated. \n",
      "Therefore, it is worthwhile for all organisations to divide the \n",
      "implementation into smaller work packages and initially focus \n",
      "on governance components that bring immediate added value \n",
      "beyond the core compliance purpose. The implementation can \n",
      "follow an agile approach in which the organisation works on \n",
      "different components at different intensities simultaneously –  \n",
      "always based on the organisational goals, the identified \n",
      "compliance risks, and time restrictions.\n",
      "The modular approach has many benefits:  \n",
      "• Quickly improving governance of AI initiatives. \n",
      "• Enhancing the quality of AI systems from the begi nning.  \n",
      "•  Successive and iterative work towards compliance  with  \n",
      "relevant requirements. In the following sections, we present several attra ctive modules \n",
      "of holistic AI governance for compliant and high-qu ality AI systems \n",
      "and highlight the specific challenges in their impl ementation.Example: A company can fall back on established \n",
      "structures in data management and, therefore, desig n \n",
      "effective processes relatively quickly. On the othe r hand, \n",
      "regarding documentation, it is better to start earl y with \n",
      "standardisation and collection – but only when it b ecomes \n",
      "necessary, for example, to push ahead with compilat ion \n",
      "and preparation for an external audit.\n",
      "Roles and responsibility structure\n",
      "The EU AI Act requires the establishment of role an d responsibility concepts for high-risk AI \n",
      "systems. It remains unclear how these shall be conc retely designed. It is, therefore, a good  \n",
      "start to fall back on best practices from other fie lds for concrete implementation. \n",
      "The necessary design varies between organisations, but the areas of responsibility and roles \n",
      "within AI systems are often similar in practice. The basis for structured processes: clear delineation \n",
      "of individual task areas and roles. Secondly, respo nsibilities for the individual task areas must be \n",
      "defined to avoid diffusion of responsibility and pr ovide clear contact persons for internal and \n",
      "external stakeholders. In the future, this will als o include auditors and regulators. \n",
      "If organisations can link work steps and roles, the y can also reduce cases where entire process \n",
      "chains collapse, e.g., due to the departure of esse ntial people because it was not clearly defined \n",
      "which areas of responsibility needed to be re-staff ed. Depending on a risk assessment, high-risk \n",
      "AI systems also lend themselves to concepts that pl ace additional requirements on the scope of \n",
      "staffing and representation of critical roles to en sure greater security and reliability.\n",
      "In role and responsibility concepts, restrictions a re necessary to meet specific security requirements , \n",
      "depending on the area of application. For example, in data management, it is (mandatory) to \n",
      "establish processes for granting and removing acces s rights to protect sensitive data. In principle, \n",
      "the actual necessity is decisive for granting such access rights (“need-to-know” basis). However, \n",
      "this is not always easy to determine in practice an d must, therefore, be clearly defined for \n",
      "decision-makers.\n",
      "May 2024Risk management\n",
      "With the use of AI, an organisation’s risk management requirements must be adapted. The EU AI \n",
      "Act requires high-risk AI systems to establish, apply and document a risk management system \n",
      "(RMS). This RMS can be understood as a continuous and iterative process that is carried out \n",
      "throughout the lifecycle of a high-risk AI system and requires regular, systematic updates. These \n",
      "can occur in defined cycles and on specific occasions, such as new findings from monitoring or \n",
      "user feedback. Furthermore, developing sufficient measures to prevent, mitigate, and reduce the \n",
      "risks to an acceptable level is required. \n",
      "The basis of adequate risk management is a systematic risk analysis. It serves to identify sources \n",
      "of risks, determine probabilities of occurrence, and quantify impacts. In the context of AI, this area \n",
      "of risk management probably poses the greatest challenges, as identifying scenarios and their \n",
      "effects requires a great deal of expertise. From degradation of performance metrics due to the \n",
      "changing characteristics of input data to discrimination due to underrepresentation, there are many \n",
      "ways in which the health, safety or fundamental rights of EU citizens or the environment can be put \n",
      "at risk. In some cases, a so-called “Fundamental Rights Impact Assessment” is also required by \n",
      "the applying organisation.\n",
      "It remains to be seen how standardisation in AI risk management will develop in the EU. Through \n",
      "international regulatory exchange, especially with the US, there is at least a willingness to harmonis e \n",
      "AI standards in many areas. This would allow the EU to build on existing international and national \n",
      "standards. For example, in January 2023, the NIST (US federal agency) published the “Artificial \n",
      "Intelligence Risk Management Framework (AI RMF 1.0)”, the first national framework for AI risk \n",
      "management. The risk management guidelines from the  joint ISO and IEC technical committee on \n",
      "artificial intelligence are also relevant (ISO/IEC 23894:2023). \n",
      "For some use cases, standardisation has already reached a higher level of maturity and detail and \n",
      "can at least provide conceptual guidance for future frameworks. One example is test scenarios for \n",
      "autonomous vehicles (ISO 34502:2022), which can help with standardised testing and subsequent \n",
      "approval. However, by no means will all organisations benefit from sector-specific standards as in \n",
      "the automotive sector. They cannot avoid determining detailed risk scenarios and probabilities of \n",
      "occurrence for their use cases. Organisations will, therefore, continue to depend on the know-how \n",
      "of (domain) experts for a comprehensive risk analysis.\n",
      "May 202414 | PwC | Trustworthy AIMay 2024Data management\n",
      "High-quality data is essential for the development of good AI systems. Data management in the  \n",
      "EU AI Act is, therefore, primarily about taking appropriate steps to achieve high data quality and \n",
      "protect data from access by unauthorised persons.\n",
      "An enormous challenge is the processing of data sets during development and operation. Thus,  \n",
      "the EU AI Act calls for specific and comprehensive quality criteria and safeguards. This results  \n",
      "in several requirements: Data sets must be assessed regularly and transparently. Organisations \n",
      "must identify and define permissible and, where appropriate, desired biases. They must check the \n",
      "availability, quantity, and suitability of the data sets and possible discrimination. Last but not least, \n",
      "they must identify potential data gaps or deficiencies.\n",
      "However, the EU AI Act does not further specify these requirements. Regulated organisations must \n",
      "determine, document, and constantly check the legal  minimum for the respective high-risk AI system \n",
      "in question. This is associated with legal uncertai nty in individual cases and may lead to liability r isks. \n",
      "Any data sets used and processed must also comply with data protection requirements in case \n",
      "they contain personal data (IP addresses, names, IDs, etc.). These requirements must be verifiably \n",
      "met at an early stage, in some cases even before th e development of the AI system begins. \n",
      "Regardless of whether the data is collected by the provider of the AI system, provided by a third \n",
      "party, or even made available (publicly) by the dat a subject, compliance must be proven. In \n",
      "addition, if copyright-protected content (e.g., texts, music) is used, it may be necessary to obtain \n",
      "corresponding rights of use in advance. \n",
      "The requirements of the GDPR extend not only to the AI system development phase (for example, \n",
      "with training data) but to the entire lifecycle of an AI system – i.e., for the input and further use as \n",
      "well as deletion and transfer of personal data. Organisations must evaluate data protection risks on \n",
      "a case-by-case basis for each form of processing of personal data in AI systems. The challenge in\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"corresponding rights of use in advance. \n",
      "The requirements of the GDPR extend not only to the AI system development phase (for example, \n",
      "with training data) but to the entire lifecycle of an AI system – i.e., for the input and further use as \n",
      "well as deletion and transfer of personal data. Organisations must evaluate data protection risks on \n",
      "a case-by-case basis for each form of processing of personal data in AI systems. The challenge in \n",
      "this context is the potential of AI systems with the principle of combining data protection through \n",
      "data protection-friendly default settings (“data protection by design”). Here, the newly adopted \n",
      "standard ISO 31700, “Privacy by design for consumer goods and services”, can provide guidance. \n",
      "Particularly delicate: Responsibilities for compliance with data protection law and AI law regulations \n",
      "can diverge. This has implications for different areas of an organisation. While the EU AI Act mainly \n",
      "addresses natural or legal persons, the GDPR links the responsibility to the body that determines \n",
      "the purposes and means of the data protection-related processing activity. Thus, it is conceivable \n",
      "that the use of a high-risk AI system in a group requires the parent company’s compliance with  \n",
      "the requirements of the EU AI Act while, at the same time, determining the means and purposes  \n",
      "of processing.\n",
      "May 202415 | PwC | Trustworthy AIMay 2024Personal employee data is primarily determined by the HR department of the subsidiary, whereby \n",
      "the subsidiary is qualified as the data protection controller. Such cases must be identified and \n",
      "documented to place the obligations of the EU AI Act in personnel terms. \n",
      "Those who deal with the legal aspects early can better assess and, at best, reduce any liability \n",
      "risks. This includes, above all, drafting contracts with providers of AI systems or actors along  \n",
      "the supply chain in an advantageous way.\n",
      "Lifecycle management\n",
      "The requirements of the EU AI Act are intended to ensure high-quality levels for all high-risk AI \n",
      "systems in the market. Therefore, the regulation places particular emphasis on structured  \n",
      "processes for the design, development, review and monitoring of AI systems. Furthermore, it \n",
      "requires that high-risk AI systems remain robust and accurate throughout their lifecycle. Combined \n",
      "with the already described requirements for responsibility management, data management and \n",
      "recording of logs and metadata, this results in the connection of abstract regulatory requirements \n",
      "to proven workflows and architectures of so-called Machine Learning Operations (MLOps).9\n",
      " Trustworthiness and compliance, at their core, require the implementation of best practices \n",
      "throughout the lifecycle of an AI system. The fundamental purpose of MLOps frameworks and \n",
      "technologies is to build structured process flows that can manage AI systems from initiation to \n",
      "operation – in some cases, even fully automatically.  \n",
      "Those who successfully combine methods from the fields \n",
      "of data management, software development and \n",
      "machine learning in MLOps enjoy far-rea-\n",
      "ching advantages for the quality and \n",
      "scaling of AI systems. Structured \n",
      "workflows make it significantly easier to \n",
      "develop and operate  \n",
      "AI systems that meet the demands of \n",
      "deployers, regulators, and providers. \n",
      "Organisations can implement lifecycle \n",
      "management with MLOps in a very \n",
      "practical way and thus create immediate \n",
      "added value for the scaling and quality assurance \n",
      "of AI systems. Prerequisite: To do this, they must be able to draw on a combination of competen-\n",
      "cies from the fields of AI development, software development, DevOps, and data technology/\n",
      "science. \n",
      "The specific challenges for high-risk AI providers are primarily to implement proven MLOps \n",
      "architectures for all their systems, to align specific principles, components, roles, and processes \n",
      "with the requirements of the EU AI Act and then to document them fully. An example of a necessary \n",
      "extension is the control and test processes for individual case-specific quality assurance, which \n",
      "can be carried out at different points in the workflow. \n",
      "The storage and monitoring of meta, input and output data is also extremely valuable, as it enables \n",
      "extended performance analyses and a higher degree o f traceability. This pays off in risk management \n",
      "and AI liability and, together with the feedback loops in MLOps, represents an advantage for the \n",
      "continuous and rapid improvement of AI systems that should not be underestimated.\n",
      "9 Kreuzberger, Kühl und Hirschl (2022): Machine Learning Operations (MLOps): Overview, Definition, and ArchitectureDeployment\n",
      "IterationDevelopment OperationsData\n",
      "Data\n",
      "Test\n",
      "TestPlan\n",
      "ning\n",
      "Tuning\n",
      "M\n",
      "odel\n",
      "RetirementAda\n",
      "ption\n",
      "MonitoringOperationIdea\n",
      "May 202416 | PwC | Trustworthy AIMay 2024Enablement of (end) users\n",
      "The EU AI Act explicitly requires users to be enabled to utilise the respective AI system.  \n",
      "Furthermore, the EU AI Act obliges system providers to provide additional transparency to people \n",
      "who interact with the AI system and use its results. Analogous to the data protection notices and \n",
      "consent to the processing of cookies (“opt-in”) via so-called cookie banners, which many are now \n",
      "familiar with from every website, AI banners and declarations could also help to implement these \n",
      "requirements and thus become widespread in the future. This is because natural persons need to \n",
      "know that they are interacting with an AI system, wh o is providing it (for any queries), what it does, \n",
      "what its technical characteristics are (e.g., the level of performance), what is expected of users and \n",
      "how to interpret the system’s results. This, too, will ultimately have an impact on any liability issues. \n",
      "However, the EU AI Act does not make any concrete specifications in this regard.\n",
      "Getting these aspects right poses several linguisti c, technical, and economic challenges. To counterac t \n",
      "fundamental uncertainties about AI systems among end users, the linguistic design must strike a \n",
      "balance between easy-to-understand language and concise texts and content that is technically \n",
      "and legally sufficient. The technical and economic challenges lie in explaining the results. It is  \n",
      "not always easy to present the connection between an AI system’s input and output. There are \n",
      "solutions for so-called “explainable AI”, but here, too, the information must be adapted to the \n",
      "expected level of knowledge of the end user. On the other hand, the intellectual property of the  \n",
      "AI provider must be protected accordingly, and no more than necessary must be revealed about \n",
      "the inner workings of an AI system.\n",
      "Conformity management\n",
      "To put high-risk systems into operation, onto the market or use their output in the EU market, \n",
      "regulated organisations must not only achieve compl iance with the AI Act but be able to demonstrate \n",
      "it. This means that based on comprehensive document ation of the individual governance components \n",
      "(“technical documentation”), compliance must be ass essed. Depending on the use case, an internal \n",
      "control system or an external body authorised to assess conformity can be used. Subsequently, \n",
      "the compliant high-risk AI system must be labelled accordingly and registered in an EU database. \n",
      "In addition, an AI provider has an obligation towards the relevant authorities to demonstrate a \n",
      "declaration of conformity and to provide access to data and documentation in case of justified \n",
      "requests. If a system is not compliant or there are incidents in operation, the relevant authorities \n",
      "must be informed and compliance restored.\n",
      "May 202417 | PwC | Trustworthy AI\n",
      "17 | PwC | Trustworthy AIMay 20241st Line of DefenceUnits TasksData Scientists\n",
      "Machine Learning  \n",
      "Developers\n",
      "MLOps Engineers\n",
      "Implementation at  \n",
      "use case level\n",
      "Documentation2nd Line of Defence\n",
      "Legal Department\n",
      "Compliance Department\n",
      "Definition of legal  \n",
      "requirements\n",
      "Establishing controls\n",
      "Standards and  \n",
      "specifications and  \n",
      "Best Practices3rd Line of Defence\n",
      "Internal Audit\n",
      "External Audit\n",
      "Independent assessment  \n",
      "of conformity with the  \n",
      "EU AI ActThe path to compliance with the EU AI Act is a team effort. Important contributions must be made \n",
      "along a wide range of functions and roles. \n",
      "While compliance departments are often responsible for laying out the requirements for documenting \n",
      "systems, the teams providing technical support for the AI system must prepare and regularly update \n",
      "the documentation. The definition of control sets a lso usually falls within the scope of the so-called  \n",
      "Second Line of Defence. However, technical and func tional teams provide evidence of compliance \n",
      "with the controls. Internal departments or external  notified bodies, which have an independent view \n",
      "of the evidence and the controls, then carry out th e final evaluation.\n",
      "One organisational challenge is to distribute respo nsibility optimally. The goal: a truthful and posit ive \n",
      "conformity assessment must be carried out, and obli gations must be fulfilled. Although documentation \n",
      "tasks are often postponed, organisations should not  avoid preparing the documents early on and in a \n",
      "disciplined manner because ex-post preparation is, in any  \n",
      "case, more time-consuming and, in some cases,  \n",
      "even impossible. So-called model maps, data  \n",
      "sheets and other technical system information  \n",
      "offer added value that goes beyond regulatory  \n",
      "compliance. In our experience, this also  \n",
      "simplifies the consolidation of best  \n",
      "practices in the development process  \n",
      "and the transition to scaled operations.\n",
      "May 202418 | PwC | Trustworthy AIThe EU AI Act will have a massive impact on the dev elopment, \n",
      "use and commercialisation of AI systems in the comi ng years. \n",
      "UK businesses along the entire AI value chain must act now. \n",
      "Early implementation of holistic AI governance and compliance \n",
      "management systems gives organisations not only a time \n",
      "advantage over the competition but also an immediat e economic \n",
      "advantage through shortened time-to-market and high quality  \n",
      "of their high-risk AI systems. The requirements are complex and\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"use and commercialisation of AI systems in the comi ng years. \n",
      "UK businesses along the entire AI value chain must act now. \n",
      "Early implementation of holistic AI governance and compliance \n",
      "management systems gives organisations not only a time \n",
      "advantage over the competition but also an immediat e economic \n",
      "advantage through shortened time-to-market and high quality  \n",
      "of their high-risk AI systems. The requirements are complex and \n",
      "present companies with new kinds of challenges that will take \n",
      "time to overcome.\n",
      "Additionally, the expected shortage of AI (governan ce) experts in \n",
      "the transitional period will likely become a signif icant cost driver. \n",
      "Organisations with high-risk use cases that do not want to wait \n",
      "several years to benefit from using AI systems in r egulated areas \n",
      "should, therefore, seize their opportunity now. If,  in addition, it  \n",
      "is possible to utilise as many synergies as possibl e with existing \n",
      "compliance structures and fall back on best practices for \n",
      "machine learning operations, organisations can buil d up the \n",
      "desired AI governance and compliance quickly and ef ficiently.\n",
      "Companies and public organisations in the UK can se t the \n",
      "course now to shape their digital transformation su ccessfully \n",
      "with the use of AI. The ability to combine quality,  compliance and \n",
      "scaling of AI systems will significantly determine the success of  \n",
      "organisations in the market. Linking these aspects requires \n",
      "interdisciplinary competencies in organisations alo ng the entire \n",
      "AI value chain. This is how to create structures an d processes \n",
      "for an AI governance that is technically, legally, and \n",
      "organisationally fit for the future.The key next steps you should be taking include:\n",
      "• Identify all Al systems in your organisation and th eir status, \n",
      "which will form the basis for decisions in establis hing \n",
      "appropriate Al governance.\n",
      "• Classify the AI systems into risk tiers and impact assess it \n",
      "against requirements of the EU Al Act, to help bett er assess \n",
      "the implications of the Al regulation on your organ isation.  \n",
      "In addition to the Al Act, other (forthcoming) hori zontal and \n",
      "sectoral regulations should also be considered, inc luding  \n",
      "any future AI legislation in the UK.\n",
      "• Assess the potential gaps and develop an execution plan to \n",
      "bridge this, ensuring that appropriate accountabili ty and \n",
      "governance is established when the AI Act comes int o force.\n",
      "• Implement employee training and increase AI awarene ss. \n",
      "Educate staff about the AI Act and its impact on th eir roles. \n",
      "This is essential to fulfill human oversight requir ements, but \n",
      "also other key requirements such as robustness test ing.  \n",
      "Doing so will demonstrate that you are proactively managing \n",
      "the risks associated with AI in your operations.4.\n",
      "Conclusion and outlook19 | PwC | Trustworthy AI\n",
      "May 2024This publication has been prepared for general guidance on matters of interest only, and does not constitute professional \n",
      "advice. You should not act upon the information contained in this publication without obtaining specific professional advice. \n",
      "No representation or warranty (express or implied) is given as to the accuracy or completeness of the information contained in \n",
      "this publication, and, to the extent permitted by law, PricewaterhouseCoopers LLP , its members, employees and agents do not \n",
      "accept or assume any liability, responsibility or duty of care for any consequences of you or anyone else acting, or refraining to \n",
      "act, in reliance on the information contained in this publication or for any decision based on it.\n",
      "© 2024 PricewaterhouseCoopers LLP . All rights reserved. ‘PwC’ refers to the UK member firm, and may sometimes refer to the \n",
      "PwC network. Each member firm is a separate legal entity. Please see www.pwc.com/structure for further details.\n",
      "RITM16580253Your contacts\n",
      "Leigh Bates \n",
      "Partner\n",
      "UK Risk AI Leader\n",
      "+44 7711 562 381\n",
      "leigh.bates@pwc.comFabrice Ciais \n",
      "Director\n",
      "AI Governance and Validation\n",
      "+44 7843 334 241\n",
      "fabrice.ciais@pwc.comChris Oxborough\n",
      "Partner\n",
      "UK Responsible AI Leader\n",
      "+44 7818 510 537\n",
      "chris.oxborough@pwc.com\n",
      "Trishia Ani \n",
      "Manager\n",
      "Data and Artificial Intelligence\n",
      "+44 7818 636970\n",
      "trishia.ani@pwc.com\n",
      "EU AI Act Governance: \n",
      "Hendrik Reese \n",
      "Partner\n",
      "Responsible AI\n",
      "+49 151 70423201\n",
      "hendrik.reese@pwc.comBanking sector: \n",
      "Konstantin Dagianis\n",
      "Partner\n",
      "Financial Services (Banks)\n",
      "+49 171 9770067\n",
      "konstantinos.dagianis@pwc.comEU AI Act Legal: \n",
      "Dr. Jan-Peter Ohrtmann\n",
      "Partner\n",
      "Data Protection\n",
      "+49 171 7614597\n",
      "jan-peter.ohrtmann@pwc.comInsurance sector:  \n",
      "David Richter\n",
      "Partner\n",
      "Financial Services \n",
      "(Insurances)\n",
      "+49 1511 0578093\n",
      "david.richter@pwc.com\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"The EU AI Act, effective May 2024, aims to standardize AI governance across EU member states, impacting both private and public sectors. It mandates robust AI governance to ensure performance, security, reliability, and fairness, which are crucial for economic efficiency and trust. The Act's extra-territorial reach affects UK businesses involved in the EU market. Compliance can mitigate risks like fines and liability claims, while fostering high-quality AI and responsible data handling. Challenges include navigating diverse regulations and skill shortages, but proper governance can streamline AI scaling and market introduction. The Act categorizes businesses into 'providers' (developers) and 'deployers' (users), with significant penalties for non-compliance, emphasizing the importance of early alignment with the regulatory framework.\n",
      "\n",
      "The document outlines the EU AI Act, which regulates AI systems within the EU and those from third countries entering the EU market. Key actors include AI providers, such as OpenAI, which develop foundational models, and users ('deployers'), who may integrate or fine-tune these models. The Act imposes obligations on providers and deployers to ensure compliance, particularly for high-risk AI systems. These systems require extensive documentation, monitoring, and quality controls. The Act also applies extraterritorially, affecting importers, distributors, and manufacturers. The regulation categorizes AI systems based on risk, prohibiting those with unacceptable risks and imposing stringent requirements on high-risk systems. Compliance challenges arise from correctly classifying AI systems and meeting legal requirements to avoid significant fines. The Act emphasizes transparency, human oversight, and data governance to protect health, safety, and fundamental rights.\n",
      "\n",
      "The EU AI Act defines AI systems and classifies high-risk AI use cases, though the exact criteria for classification will be clarified through case law and recognized interpretative methods. Compliance with these classifications is crucial due to the EU AI Liability Directive, which imposes liability for damages caused by AI systems and presumes causality under certain conditions. High-risk AI systems must meet extensive requirements, posing challenges for integration into existing technical and organizational processes. Effective compliance necessitates bundling legal risk assessments into a unified process within a compliance management system. Additionally, the EU needs to ensure standardization to promote innovation while addressing practical implementation challenges, such as human oversight in AI systems.\n",
      "\n",
      "Organizations developing, operating, or distributing AI systems must prepare compliance and governance components, involving qualified personnel and cross-functional training. Conducting impact and gap assessments will help evaluate the regulatory impact and identify necessary compliance measures. These steps aim to ensure both high-quality AI systems and compliance, facilitating sustainable value creation with AI.\n",
      "\n",
      "The document outlines how organizations can prepare for and comply with the EU AI Act and other related regulations. It emphasizes conducting impact assessments for AI use cases, performing gap assessments to align existing processes with compliance requirements, and developing a comprehensive compliance strategy. Key steps include integrating AI governance into IT governance, managing AI-specific risks, and ensuring high data quality. The modular approach to implementation is recommended, focusing on immediate benefits and iterative compliance. It also discusses the importance of clear roles and responsibilities, robust risk management, and stringent data management to meet regulatory standards while mitigating legal uncertainties and liability risks.\n",
      "\n",
      "The document outlines the comprehensive requirements for AI systems under the GDPR and the EU AI Act, emphasizing the need for data protection throughout the AI lifecycle. It highlights the importance of evaluating data protection risks, implementing data protection-friendly settings, and adhering to standards like ISO 31700. Responsibilities for compliance can diverge within organizations, necessitating thorough documentation and contract management. The EU AI Act mandates high-quality standards for high-risk AI systems, necessitating robust lifecycle management and MLOps frameworks to ensure compliance, transparency, and continuous improvement. Additionally, the Act requires user enablement and transparency akin to data protection notices. Compliance involves comprehensive documentation, internal and external assessments, and the labeling of compliant AI systems. Organizations must distribute responsibilities effectively and prepare documentation early to streamline conformity assessments and best practices. Early adoption of AI governance systems offers competitive and economic advantages.\n",
      "\n",
      "UK businesses must act swiftly to implement holistic AI governance and compliance systems to gain a competitive and economic edge through faster time-to-market and higher quality AI systems. The complexity of AI requirements and a potential shortage of experts could drive costs, so companies should leverage existing compliance structures and best practices. Key steps include identifying and assessing AI systems, classifying them by risk, addressing regulatory gaps, and training employees. Success in the AI market will depend on integrating quality, compliance, and scalability, necessitating interdisciplinary competencies. This guidance underscores the need for proactive risk management and readiness for forthcoming regulations like the EU AI Act.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = summary_chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The EU AI Act, effective May 2024, aims to standardize AI governance across EU member states, affecting both private and public sectors and extending its reach to UK businesses involved in the EU market. It mandates robust governance to ensure AI performance, security, reliability, and fairness. The Act categorizes entities into AI 'providers' (developers) and 'deployers' (users), imposing stringent requirements and significant penalties for non-compliance, particularly for high-risk AI systems. Compliance involves extensive documentation, monitoring, and quality controls, alongside transparency, human oversight, and data governance to protect health, safety, and fundamental rights.\\n\\nOrganizations must prepare by conducting impact and gap assessments, integrating AI governance into broader IT governance, managing AI-specific risks, and ensuring high data quality. The Act's alignment with the GDPR highlights the need for data protection throughout the AI lifecycle, necessitating robust lifecycle management and MLOps frameworks. Effective compliance requires clear roles, thorough documentation, and proactive risk management, offering competitive advantages and facilitating sustainable value creation. UK businesses must act swiftly to implement holistic AI governance to gain a market edge, leveraging existing compliance structures and best practices to address regulatory gaps and train employees.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
